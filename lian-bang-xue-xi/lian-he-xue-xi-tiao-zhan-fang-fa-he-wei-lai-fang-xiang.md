# paer2-联合学习:挑战、方法和未来方向

原文链接：[联合学习:挑战、方法和未来方向](https://arxiv.org/abs/1908.07873v1)

## 摘要

联邦学习包括在远程设备或竖井数据中心\(如移动电话或医院\)上训练统计模型，同时保持数据本地化。在异构和潜在的大规模网络中的训练引入了新的挑战，需要从根本上背离大规模机器学习、分布式优化和隐私保护数据分析的标准方法。在这篇文章中，我们讨论了联邦学习的独特特征和挑战，提供了当前方法的广泛概述，并概述了与广泛的研究社区相关的未来工作的几个方向。

## 1 引言

移动电话、可穿戴设备和自动驾驶汽车只是现代分布式网络中的一小部分，每天都会产生大量数据。由于这些设备不断增长的计算能力——加上对传输私人信息的关注——本地存储数据和将网络计算推向边缘越来越有吸引力。

边缘计算的概念并不新鲜。事实上，跨分布式、低功耗设备计算简单查询是一个长达数十年的研究领域，已经在传感器网络查询处理、边缘计算和雾计算的范围内进行了探索\[12,29,40,49,74\]。最近的研究也考虑了集中训练机器学习模型，但在本地服务和存储它们;例如，这是移动用户建模和个性化的常用方法\[60,90\]。

然而，随着分布式网络中设备的存储和计算能力的增长，可以利用每个设备上增强的本地资源。这导致了人们对联邦学习的兴趣不断增长\[75\]，该学习探索直接在远程设备上训练统计模型\[1\]。正如我们在本文中讨论的，在这样的环境中学习与传统的分布式环境有很大的不同——需要隐私、大规模机器学习和分布式优化等领域的基本进展，并在不同领域的交叉领域提出了新问题，如机器学习和系统\[91\]。

![image-20210415170935044](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper2/figure-1.png)

图1：手机下一个单词预测任务的联合学习应用示例。为了保护文本数据的隐私并减少网络上的压力，我们寻求以分布式方式训练预测器，而不是将原始数据发送到中央服务器。在这种设置中，远程设备定期与中央服务器通信，以学习全局模型。在每一轮通信中，选定的手机的一个子集对其分布不同的用户数据进行本地训练，并将这些本地更新发送到服务器。合并更新之后，服务器然后将新的全局模型发送回设备的另一个子集。这种迭代训练过程在网络中持续进行，直到达到收敛或满足某个停止准则。

联邦学习方法已被主要的服务提供商部署\[11,124\]，并在支持隐私敏感的应用程序中发挥了关键作用，这些应用程序的训练数据分布在边缘\[例如。， 5, 46, 51, 89, 105, 127, 139\]。潜在的应用包括：情感学习，语义定位，或手机用户的活动；适应自动驾驶汽车中的行人行为；以及预测可穿戴设备引发的心脏病等健康事件\[6,52,84\]。下面我们讨论几个联邦学习的规范应用：

* **智能手机。**通过在一个巨大的手机池学习用户行为，统计模型可以为下一个词预测、人脸检测和语音识别等应用提供动力\[46,89\]。然而，用户可能不愿意分享他们的数据，以保护他们的个人隐私或节省他们手机的有限的带宽/电池电力。联邦学习有潜力在智能手机上启用预测功能，而不会减少用户体验或泄露私人信息。图1描述了一个这样的应用程序，在这个应用程序中，我们的目标是基于用户的历史文本数据\[46\]在大规模移动电话网络中学习下一个单词预测器。
* **组织。**组织或机构也可以被视为联合学习环境中的“设备”。例如，医院是一些组织，它们包含大量用于预测性医疗保健的患者数据。然而，医院在运营中有严格的隐私惯例，可能会面临法律、行政或道德方面的限制，要求数据保留在本地。联邦学习是\[52\]这些应用程序的一个有前途的解决方案，因为它可以减少网络的压力，并允许各种设备/组织之间的私人学习。
* **物联网。**现代物联网网络，如可穿戴设备、自动驾驶汽车或智能家居，可能包含大量传感器，使它们能够实时收集、反应和适应传入数据。例如，一个自动驾驶车队可能需要最新的交通，建筑或行人行为模型来安全操作。然而，由于数据的私有性质和每个设备的有限连接，在这些场景中构建聚合模型可能很困难。联邦学习方法可以帮助训练模型，有效地适应这些系统中的变化，同时保持用户隐私\[84,98\]。

### 1.1 问题公式化

规范联邦学习问题涉及从存储在数千万到数百万远程设备上的数据中学习单个的、全局的统计模型。我们的目标是在设备生成的数据在本地存储和处理，只有中间更新定期与中央服务器通信的约束下学习这个模型。特别是，目标通常是最小化以下目标函数：

$$
\mathop{min}\limits_{w}F(w),\ where\ F(w):=\sum\limits_{k=1}^mp_kF_k(w)
$$

其中，m为设备总数，pk≥0，∑kpk= 1, Fkis为第k个设备的局部目标函数。局部目标函数通常定义为局部数据的经验风险，即Fk\(w\) =1 nk∑nk jk=1fjk\(w;xjk,yjk\)，其中nkis为局部可用的样本数。用户定义术语pkk指定每个设备的相对影响，两个自然设置pk=1或pk=nk n，其中n =∑knkis为样本总数。我们将在整篇文章中引用问题\(1\)，但是，正如下面所讨论的，我们注意到其他目标或建模方法可能是适当的，这取决于感兴趣的应用程序。

### 1.2 核心挑战

接下来，我们将描述与解决\(1\)中提出的分布式优化问题相关的四个核心挑战。这些挑战使联邦设置不同于其他经典问题，如数据中心设置中的分布式学习或传统的私有数据分析。

**挑战1：昂贵的通讯费用。**在联邦网络中，通信是一个关键的瓶颈，再加上发送原始数据时的隐私问题，使得在每个设备上生成的数据必须保持在本地。事实上，联邦网络可能由大量设备组成，例如数百万部智能手机，网络中的通信可能比本地计算慢许多个数量级\[50,115\]。为了适应数据模型生成的联合网络设备，因此有必要开发communication-efficient迭代方法发送小消息或模型更新训练过程的一部分，而不是通过网络发送整个数据集。要在这种情况下进一步减少通信，需要考虑的两个关键方面是：\(i\)减少通信轮的总数，或\(ii\)减少每轮传输信息的大小。

**挑战2：系统异构性。**联邦网络中每个设备的存储、计算和通信能力可能因硬件\(CPU、内存\)、网络连接性\(3G、4G、5G、wifi\)和电源\(电池电量\)的不同而不同。此外，每个设备上的网络大小和系统相关的限制通常导致只有一小部分设备同时处于活动状态，例如，在一个百万设备的网络\[11\]中有数百个活动设备。每个设备也可能是不可靠的，活跃设备在给定迭代中由于连接或能量限制而退出的情况并不罕见。这些系统级的特征极大地加剧了诸如掉队缓解和容错等挑战。因此，开发和分析的联邦学习方法必须：\(i\)预期低参与度，\(ii\)容忍异构硬件，以及\(iii\)对网络中的丢弃设备具有鲁棒性。

**挑战3：统计上的异质性。**设备经常以不同的方式在网络上生成和收集数据，例如，移动电话用户在下一个单词预测任务的上下文中使用不同的语言。此外，设备之间的数据点数量可能会有很大的差异，并且可能存在一个捕获设备及其相关分布之间的关系的底层结构。这种数据生成范式违反了分布式优化中经常使用的独立和同分布\(I.I.D.\)假设，增加了掉线的可能性，并可能增加建模、分析和评估方面的复杂性。的确，虽然\(1\)中的规范联邦学习问题的目标是学习单个全局模型，但也存在其他替代方法，如通过多任务学习框架\[cf.\]同时学习不同的局部模型。106\]。在这方面，联邦学习和元学习的主要方法之间也有密切的联系\[64\]。多任务和元学习视角都支持个性化或设备特定的建模，这通常是处理数据统计异质性的更自然的方法。

**挑战四：隐私问题。**最后，隐私通常是联邦学习应用程序的主要关注点。联邦学习通过共享模型更新，例如梯度信息，而不是原始数据，向保护每个设备上生成的数据迈出了一步\[17,31,33\]。然而，在整个训练过程中，模型更新的通信仍然可以向第三方或中央服务器披露敏感信息\[76\]。虽然最近的方法旨在使用安全多方计算或差分隐私等工具增强联邦学习的隐私性，但这些方法通常以降低模型性能或系统效率为代价提供隐私。从理论和经验上理解和平衡这些权衡，是实现私有联合学习系统的一个相当大的挑战。

本文的其余部分组织如下。在第2节中，我们将介绍以前和当前的工作，这些工作旨在解决所讨论的联邦学习的四个挑战。在第三部分，我们概述了未来研究的几个有希望的方向。

## 2 目前以及相关工作的调查

联邦学习的挑战乍一看类似于隐私、大规模机器学习和分布式优化等领域的经典问题。例如，在机器学习、优化和信号处理领域，已经提出了许多方法来解决昂贵的通信。然而，这些方法通常不能完全处理联邦网络的规模，更不用说系统和统计异构性的挑战了。同样，虽然隐私是许多机器学习应用程序的一个重要方面，但由于数据的统计变化，联邦学习的隐私保护方法很难严格地断言，由于每个设备上的系统限制以及跨潜在的大规模网络，实现起来可能会更加困难。在本节中，我们将更详细地探讨第1节中提出的挑战，包括对经典结果的讨论以及专门关注联邦学习的最新工作。

![image-20210415173437293](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper2/figure-2.png)

图2:左边:分布式\(小批量\)SGD。每个设备k局部计算从一小批数据点的梯度来近似$\nabla F\_k\(w\)$，并将聚合的小批更新应用于服务器上。右图:本地更新方案。每个设备立即应用本地更新，例如，梯度，在他们被计算和服务器执行一个全局聚合后，可变数量的本地更新。本地更新方案可以通过在本地执行额外的工作来减少通信

### 2.1 通信效率

在为联邦网络开发方法时，通信是需要考虑的一个关键瓶颈。虽然对通信高效的分布式学习方法进行完整的回顾超出了本文的范围，但我们指出了几个主要的方向，我们将其分为\(1\)本地更新方法，\(2\)压缩方案，\(3\)分散训练。

#### 2.1.1 本地更新

小批量优化方法将经典随机方法扩展到一次处理多个数据点，已成为数据中心环境中分布式机器学习的流行范式\[28,88,96,102,103\]。然而，在实践中，它们的灵活性被证明是有限的，无法适应最大限度地利用分布式数据处理的通信-计算权衡\[107,108\]。为此，最近提出了几种方法来提高分布式环境下的通信效率，方法是允许在每个通信轮上并行地在每台机器上应用可变数量的本地更新，使计算量相对于通信量更加灵活。对于凸目标，分布式局部更新原始对偶方法已经成为解决这类问题的一种流行方法\[54,62,72,107,128\]。这些方法利用二元结构，有效地将全局目标分解为子问题，并在每一轮通信中并行解决。一些分布式的局部更新原始方法也被提出，它们的额外好处是适用于非凸目标\[93,136\]。这些方法在实践中大大提高了性能，与传统的小批处理方法或分布式方法\(如ADMM\[14\]\)相比，在真实的数据中心环境中，这些方法可以实现数量级的加速。我们在图2中直观地说明了本地更新方法。

在联邦设置中，允许灵活的本地更新和低客户参与的优化方法已经成为事实上的解决方案\[65,75,106\]。联邦学习最常用的方法是联邦平均法\(federingaveraging, FedAvg\)\[75\]，这是一种基于对原始问题的局部随机梯度下降\(local stochastic gradient descent, SGD\)更新的平均方法。FedAvg在经验上表现得很好，特别是对于非凸问题，但它没有收敛性保证，并且在实际设置中，当数据是异构的时，可能会产生分歧\[65\]。我们将在2.3.2节中更详细地讨论处理这种统计异质性的方法。

![image-20210415174258588](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper2/figure-3.png)

图3：集中式与分散式拓扑。在典型的联邦学习设置中，作为本文的重点，我们假设一个星型网络\(左\)，其中服务器连接所有远程设备。当与服务器的通信成为瓶颈时，分散式拓扑\(右\)是一个潜在的替代方案。

#### 2.1.2 压缩方案

本地更新方法可以减少通信轮数，而稀疏化、子采样、量化等模型压缩方案可以显著减少每轮通信的消息大小。对于数据中心环境下的分布式训练，这些方法已经在之前的文献中得到了广泛的实证和理论研究；我们把读者推迟到\[119,135\]以获得更完整的评论。在联邦环境中，设备的低参与、非同一分布的本地数据和本地更新方案对这些模型压缩方法提出了新的挑战。例如，经典分布式学习\[101\]中常用的错误补偿技术不能直接扩展到联合设置，因为如果设备不经常采样，本地积累的错误可能会过时。然而，一些研究已经在联邦设置中提供了实用的策略，如强制更新模型为稀疏和低秩；利用结构化随机旋转\[59\]进行量化利用有损压缩和dropout减少服务器与设备之间的通信\[15\]并应用Golomb无损编码\[99\]。从理论的角度来看，虽然之前的工作已经探索了在非同分布数据\(例如:， 111\]，所做的假设没有考虑到联邦设置的共同特征，如低设备参与或本地更新优化方法。

#### 2.1.3 分散训练

在联邦学习中，星型网络\(中央服务器连接到设备网络，如图3的左图\)是主要的通信拓扑结构；因此，在本文中，我们将重点放在恒星网络设置上。然而，作为一种潜在的替代方案，我们将简要讨论去中心化拓扑\(设备只与它们的邻居通信，例如图3中的右面板\)。在数据中心环境中，当在低带宽或高延迟的网络上运行时，分散训练已被证明比集中训练更快；我们让读者阅读\[47,67\]以获得更全面的回顾。同样，在联邦学习中，分散算法理论上可以降低中央服务器上的高昂通信成本。最近的一些研究\[47,61\]用局部更新方案研究了异构数据上的分散训练。然而，它们要么限于线性模型\[47\]，要么假定全设备参与\[61\]。最后，层次通信模式也被提出\[68,70\]，以进一步减轻中央服务器的负担，首先利用边缘服务器聚合来自边缘设备的更新，然后依靠云服务器聚合来自边缘服务器的更新。虽然这是一种很有前景的减少通信的方法，但它并不适用于所有的网络，因为这种类型的物理层次可能不存在或已知的先验。![image-20210416174912459](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper2/figure-4.png)

图4：联合学习中的系统异构性。设备可能在网络连接、电源和硬件方面有所不同。此外，在训练过程中，有些设备可能随时掉线。因此，联合训练方法必须容忍异构的系统环境和设备的低参与度，也就是说，它们必须允许每轮只有一小部分设备处于活动状态。

### 2.2 系统异构性

在联邦设置中，由于设备在硬件、网络连接性和电池功率方面可能有所不同，因此跨网络的系统特性存在显著的变化。如图4所示，与典型的数据中心环境相比，这些系统特征使得掉队等问题明显更为普遍。我们粗略地将处理系统异构的几个关键方向分为：\(i\)异步通信，\(ii\)主动设备采样，\(ii\)容错。如2.1.3节所述，在接下来的讨论中，我们假设使用星型拓扑。

#### 2.2.1 异步通信

在传统的数据中心设置中，同步和异步两种方案都常用来并行化迭代优化算法，每种方法各有优缺点。同步方案简单，保证串行等效计算模型，但他们也更容易在设备变化方面掉队。异步方案是减少异构环境中掉线的一种很有吸引力的方法，特别是在共享内存系统中\[27,30,48,92,141\]。然而，它们通常依赖于有限制的延迟假设来控制过时的程度，对于设备k来说，这取决于自设备k从中央服务器拉出以来更新的其他设备的数量。异步参数服务器在分布式数据中心已经取得了成功，经典的有界延迟假设在联邦设置中可能是不现实的，在联邦设置中，延迟可能是小时到天的顺序，或完全无界。

#### 2.2.2 活跃的抽样

在联邦网络中，通常只有一小部分设备参加每一轮的训练。然而，绝大多数联邦方法，例如\[11,47,65,75,106\]中描述的那些方法，都是被动的，因为它们的目的不是影响哪些设备参与其中。另一种方法是在每一轮中积极选择参与设备。例如，Nishio和Yonetani\[83\]探索了基于系统资源的新颖设备采样策略，目的是让服务器在预定义的时间窗口内聚合尽可能多的设备更新。同样，Kang等人在设计激励机制以鼓励拥有更高质量数据的设备参与学习过程时，考虑了每个设备上产生的系统开销。然而，这些方法假定网络的系统特征是静态模型;如何扩展这些方法来处理实时的、特定于设备的计算和通信延迟的波动仍然是一个开放的问题。此外，尽管这些方法主要关注系统可变性来进行主动采样，但我们注意到，也值得考虑基于底层统计结构对一组小型但具有充分代表性的设备进行主动采样。

#### 2.2.3 容错

容错在系统群体中得到了广泛的研究，是经典分布式系统的基本考虑因素\[19,71,110\]。最近的研究还针对数据中心环境中的机器学习工作负载进行了容错研究。\[例如： 87, 112\]。然而，当通过远程设备进行学习时，容错变得更加重要，因为一些参与设备在完成给定的训练迭代\[11\]之前的某个点退出是很常见的。一个实用的策略是简单地忽略这种设备故障\[11\]，如果故障设备具有特定的数据特征，则可能在设备采样方案中引入偏差。例如，来自偏远地区的设备可能会因为网络连接差而更容易掉包，因此训练过的联邦模型会偏向于网络条件好的设备。从理论上讲，虽然最近的一些工作已经研究了联邦学习方法变量的收敛性保证\[56,123,131,132\]，很少有分析允许低参与率\[例如。， 65, 106\]，或直接研究掉落装置的影响。

编码计算是通过引入算法冗余来容忍设备故障的另一种选择。最近的研究已经探索了使用代码来加速分布式机器学习训练\[例如，20, 21, 63, 94, 109\]。例如，在存在掉线的情况下，梯度编码及其变体\[20,21,109\]小心地跨计算节点复制数据块\(以及这些数据块上的梯度计算\)，以获得准确或不准确的真实梯度恢复。尽管对于联邦设置来说，这似乎是一种很有前途的方法，但这些方法在联邦网络中面临着根本性的挑战，因为隐私限制和网络规模的关系，跨设备共享数据/复制往往是不可行的。

### 2.3 统计异质性

当从不同设备上分布的数据来训练联合模型时，在数据建模\(如图5所示\)和分析相关训练过程的收敛行为方面都会遇到挑战。我们在下面的这些方向上讨论相关的工作。

#### 2.3.1 异构数据建模

有大量的机器学习文献通过元学习\[114\]和多任务学习\[18,37\]等方法模拟了统计异质性；这些想法最近已经扩展到联邦环境\[24,26,35,58,106,138\]。例如，MOCHA\[106\]，一个为联邦设置设计的优化框架，可以通过为每个设备学习独立但相关的模型来实现个性化，同时通过多任务学习利用共享表示。该方法对考虑的目标具有可证明的理论收敛性保证，但其能力有限对于适用大规模网络，且局限于凸目标。另一种方法\[26\]将星形拓扑建模为贝叶斯网络，并在学习过程中进行变分推理。虽然这种方法可以处理非凸模型，但推广到大型联邦网络是昂贵的。Khodak等人\[58\]证明了使用多任务信息\(每个任务对应一个设备\)的任务内学习率，并证明了比普通FedAvg改进的经验性能。Eichner等人\[35\]研究了一种多元解决方案\(在全局模型和特定设备模型之间进行自适应选择\)，以解决联合训练期间数据样本中的循环模式。Zhao等人\[138\]在一些共享代理数据上集中训练了一个全局模型后，运行FedAvg来探索个性化迁移学习。尽管最近取得了这些进展，但关键的挑战仍然是在联邦设置中为异构建模提供健壮、可伸缩和自动化的方法。

![image-20210420172225200](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper2/figure-5.png)

图5：联邦网络中的不同建模方法。根据数据、网络和感兴趣的应用的属性，人们可以选择\(a\)为每个设备学习单独的模型，\(b\)将一个单一的全局模型适用于所有设备，或\(c\)学习网络中相关但不同的模型。

在为联邦数据建模时，考虑精度之外的问题也很重要，比如公平性。特别是，像\(1\)中那样天真地解决累计损失函数可能会隐含地对某些设备有利或不利，因为所学习的模型可能会偏向具有更大数据量的设备，或\(如果设备权重相等\)倾向于常见的设备组。最近的工作提出了改进的建模方法，旨在减少模型性能在设备之间的差异。一些启发式方法简单地根据本地丢失\[52\]执行不同数量的本地更新。其他更有原则的方法包括不可知联邦学习\[80\]，它通过极大极小优化方案，对由客户端分布混合形成的任何目标分布优化集中模型。Li等人采用了另一种更普遍的方法\[66\]，他们提出了一种被称为q-FFL的目标，在该目标中，损耗较高的设备被赋予更高的相对权重，以减少最终精度分布中的差异。除了公平性问题，我们注意到联邦学习中的问责制和可解释性等方面也值得探讨，但由于网络的规模和异质性，可能具有挑战性。

#### 2.3.2 非iid数据的收敛性保证

统计异质性在分析联邦设置中的收敛行为方面也提出了新的挑战——即学习单个全局模型。事实上，当数据在网络中的设备上不是相同分布时，像FedAvg这样的方法在实践中已经被证明是不同的\[65,75\]。并行SGD和相关的变种，使本地更新类似于FedAvg，已经被分析在I.I.D.设置\[68,93,104,108,120,121,122,125,136,140\]。然而，结果依赖于这样一个前提，即每个局部求解器都是同一个随机过程的副本\(由于I.I.D.假设\)，而在典型的联邦设置中并非如此。为了了解FedAvg在统计上不同的环境下的性能，最近有人提出了FedProx\[65\]。FedProx对FedAvg方法做了一个小的修改，以帮助确保在理论上和实践中收敛。FedProx也可以被解释为FedAvg的一个广义的、重新参数化的版本，在考虑跨设备的系统异构性方面具有实际的影响。其他一些著作\[56,123,131,132\]也探讨了不同假设下异构数据的收敛性保证，例如凸性\[123\]或一致有界梯度\[131\]。还有一些启发式方法旨在处理统计异质性，可以通过共享本地设备数据或一些服务器端代理数据\[52,55,138\]。然而,这些方法可能是不现实的：除了对网络带宽的负担,向服务器发送本地数据\[55\]违反联合学习的关键隐私假设，以及发送全局共享代理数据，所有设备\(138\)需要努力认真生成或收集这样的辅助数据。

### 2.4 隐私

隐私方面的考虑常常促使人们需要在联邦设置中将原始数据保存在每个设备的本地。然而，作为训练过程的一部分，共享模型更新等其他信息也可能泄露敏感的用户信息\[8,17,39,78\]。例如，Carlini等人的\[17\]证明，人们可以从根据用户语言数据训练的递归神经网络中提取敏感的文本模式，例如，特定的信用卡号码。鉴于对保护隐私学习方法的兴趣日益增加，在第2.4.1节中，我们首先简要回顾了之前在一般\(分布式\)机器学习设置中增强隐私的工作。然后，我们将在第2.4.2节中回顾最近专门为联邦设置设计的隐私保护方法。

#### 2.4.1 机器学习中的隐私

隐私保护学习已经在机器学习\[例如：76\]，系统\[例如：4，11\]以及理论\[例如，38，39\]社区中得到广泛研究。我们将简要回顾三种主要策略，包括传输有噪声数据草图的差分隐私、对加密数据进行操作的同态加密以及安全函数评估或多方计算。

在这些隐私保护方法中，差分隐私\[32,33,34\]因其具有较强的信息理论保障能力、算法简单性和相对较小的系统开销而被广泛应用。简单地说，如果一个输入元素的改变不会导致输出分布的太大差异，那么随机机制是不同的私有的；这意味着对于学习过程中是否使用了特定的样本，我们无法得出任何结论。这样的样本级隐私可以在许多学习任务中实现\[2,7,22,53,85,86\]。对于基于梯度的学习方法，一种流行的方法是通过在每次迭代时随机扰动中间输出来应用差分隐私。， 2, 7, 126\]。在应用扰动之前，例如，通过高斯噪声\[2\]，拉普拉斯噪声\[77\]，或二项噪声\[3\]，通常剪辑梯度，以限制每个示例对整体更新的影响。在差分隐私和模型精度之间存在固有的权衡，因为增加更多的噪声会导致更大的隐私，但可能会显著损害精度。尽管差别隐私实际上是机器学习中隐私的度量标准，但还有许多其他隐私定义，如k-匿名\[36\]、δ-presence\[81\]和距离相关\[117\]，这些定义可能适用于不同的学习问题\[118\]。

![image-20210420173838979](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper2/figure-6.png)

\(a\)无额外隐私保护机制的联邦学习。\(b\)全局隐私，假设有一个受信任的服务器。\(c\)本地隐私，其中中央服务器可能是恶意的。

图6：在一次联邦学习中不同的隐私增强机制的说明。M表示用于私有化数据的随机机制。使用全局隐私\(b\)，模型更新对除单个受信任方\(中央服务器\)之外的所有第三方都是私有的。使用本地隐私\(c\)，单个模型更新对服务器也是私有的。

除了差分隐私之外，同态加密还可以通过对加密数据的计算来保护学习过程，尽管目前它被应用于有限的设置，如训练线性模型\[82\]或仅涉及少数实体\[133\]。当敏感数据集分布在不同的数据所有者之间时，另一个自然的选择是通过安全函数评估\(SFE\)或安全多方计算\(SMC\)来执行隐私保护学习。由此产生的协议可以使多方协同计算一个一致同意的函数，而不会泄漏任何一方的输入信息，除了可以从输出中推断出来的信息\(例如:， 23, 43, 95\]。因此，SMC虽然不能保证对信息泄露的保护，但可以与差分隐私相结合，实现更强的隐私保障。然而，这些方法可能不适用于大规模的机器学习场景，因为它们会产生大量额外的通信和计算成本。此外，针对目标学习算法中的每一个操作，都需要精心设计和实现SMC协议\[25,79\]。我们让感兴趣的读者阅读\[13,97\]，以便对基于同态加密和SMC的方法进行更全面的回顾。

#### 2.4.2 联邦学习中的隐私

联邦设置对现有的隐私保护算法提出了新的挑战。除了提供严格的隐私保障外，有必要开发计算成本低、通信效率高、对掉线设备容忍度高的方法——所有这些都不会过度损害准确性。虽然联邦学习中的隐私定义多种多样\[8,17,41,64,76,113\]，但通常可以分为两类：全局隐私和本地隐私。如图6所示，全局隐私要求每轮生成的模型更新对除中央服务器之外的所有不受信任的第三方都是私有的，而本地隐私进一步要求更新对服务器也是私有的。

目前旨在提高联邦学习的隐私性的工作通常建立在以前的经典密码协议上，如SMC\[10,42\]和差分隐私协议\[3,8,41,76\]。Bonawitz等人的\[10\]引入了一种SMC协议来保护单个模型的更新。中央服务器不能看到任何本地更新，但仍然可以观察每一轮的准确聚合结果。SMC是一种无损的方法，可以在保证很高的隐私性的前提下保持原有的精度。然而，由此产生的方法会产生显著的额外通信成本。其他著作\[41,76\]将差分隐私应用于联邦学习并提供全局差分隐私。这些方法有许多影响通信和准确性的超参数，必须谨慎选择，尽管后续工作\[113\]提出了自适应梯度裁剪策略来帮助缓解这个问题。在需要更强的隐私保障的情况下，Bhowmick等人\[8\]通过限制潜在对手的力量，引入了本地隐私的宽松版本。它提供了比全局隐私更强的隐私保障，比严格的本地隐私有更好的模型性能。Li等人\[64\]提出了元学习环境下的局部差分私有算法，该算法可应用于个性化联合学习，同时也提供了凸设置下的可证明的学习保证。此外，差分隐私可以与模型压缩技术相结合，减少通信，同时获得隐私利益。

## 3 未来的发展方向

联合学习是一个活跃的和正在进行的研究领域。虽然最近的工作已经开始解决第2节讨论的挑战，但仍有一些关键的开放方向有待探索。在本节中，我们简要概述了围绕前面讨论的挑战\(昂贵的通信、系统异构性、统计异构性和隐私问题\)的一些有前途的研究方向，并介绍了与联邦设置中的产品化和基准测试等问题有关的其他挑战。

* **极端的通信方案。**联邦学习中需要多少通信还有待观察。事实上，众所周知，机器学习的优化方法可以容忍精度的缺乏；这个错误实际上有助于泛化\[129\]。虽然在传统的数据中心设置中已经探索了一次性或分治通信方案\[73,137\]，但这些方法的行为在大规模或统计异构网络中还没有得到很好的理解。类似地，最近已经提出了用于联邦设置的一次性/少量启发式方法\[44,45,134\]，但还没有在规模上进行理论分析或评估。
* **通信减少和Pareto边界。**我们讨论了在联邦训练中减少通信的几种方法，如本地更新和模型压缩。为了创建一个用于联邦学习的现实系统，重要的是要理解这些技术如何相互组合，并系统地分析每种方法的准确性和通信之间的权衡。特别是，最有用的技术将展示在帕雷托边界的改进——在相同的通信预算下，实现比任何其他方法更大的精度，理想情况下，跨越广泛的通信/精度剖面。对于高效的神经网络推理，也进行了类似的综合分析，并且为了以一种有意义的方式比较联邦学习的通信减少技术是必要的。
* **新颖的异步模型。**正如2.2.1节所讨论的，分布式优化中最常研究的两种通信方案是批量同步方法和异步方法\(假定延迟有界\)。这些方案在数据中心设置中更为现实——工作节点通常用于处理工作负载，也就是说，它们在“推送”上一项工作的结果后，准备立即从中心节点“拉动”下一项工作。相反，在联邦网络中，每个设备通常不专门用于手头的任务，大多数设备在任何给定的迭代中都不活跃。因此，值得研究这种更现实的以设备为中心的通信方案的效果——每个设备可以决定何时“唤醒”，并以事件触发的方式与中心服务器交互。
* **异构性诊断。**最近的研究旨在通过度量来量化统计异质性，如局部不相似性\(在\[65\]的联邦学习环境中定义，并在\[100,116,130\]的研究中用于其他目的\)和推土机的距离\[138\]。然而，在训练之前，这些指标很难在联邦网络上计算出来。这些指标的重要性引发了以下开放的问题：\(i\)是否存在简单的诊断，可以预先快速确定联邦网络的异构程度?\(ii\)可以开发类似诊断来量化系统相关异构性的数量吗?\(iii\)是否可以利用现有的或新的异构定义进一步提高联邦优化方法的收敛性?
* **细粒度的隐私约束。**第2.4.2节中概述的隐私定义涵盖了网络中所有设备在本地或全球层面上的隐私。然而，在实践中，可能有必要在更细粒度上定义隐私，因为隐私约束可能在不同设备之间，甚至在单个设备上的数据点之间存在差异。例如，Li等人\[64\]最近提出了特定于样本\(而不是特定于用户\)的隐私保障，从而提供了一种较弱的隐私形式，以换取更精确的模型。开发处理混合\(特定设备或特定样本\)隐私限制的方法是未来工作的一个有趣且正在进行的方向。
* **监督学习。**值得注意的是，到目前为止讨论的方法都是基于监督学习的任务开发的，也就是说，它们假设联邦网络中的所有数据都存在标签。在实践中，在实际的联邦网络中生成的许多数据可能是未标记的或弱标记的。此外，当前的问题可能不是将模型与\(1\)中所示的数据相匹配，而是执行一些探索性数据分析、确定总体统计数据或运行更复杂的任务，如强化学习。在联邦网络中解决监督学习之外的问题可能需要解决类似的可伸缩性、异构性和隐私方面的挑战
* **Productionizing联合学习。**除了本文讨论的主要挑战之外，在生产环境中运行联邦学习还会出现许多实际问题。特别是，诸如概念漂移\(当底层数据生成模型随时间变化时\)等问题;日变化\(当设备在一天或一周的不同时间表现出不同的行为\)\[35\];冷启动问题\(当新设备进入网络时\)必须小心处理。我们把读者的注意力放在\[11\]上，它讨论了在生产联合学习系统中存在的一些与系统相关的实际问题。
* **基准。**最后，由于联合学习是一个新兴领域，我们正处于塑造该领域发展的关键时刻，并确保它们植根于现实世界的设置、假设和数据集。对于更广泛的研究团体来说，在现有实现和基准工具\(如LEAF\[16\]和TensorFlow Federated\[1\]\)的基础上进一步构建是至关重要的，以促进实证结果的重现性和联邦学习新解决方案的传播。

## 4 结论

在本文中，我们提供了联邦学习的概述，这是一种在分布式网络的边缘训练统计模型的学习范式。与传统的分布式数据中心计算和经典的隐私保护学习相比，我们讨论了联邦学习的独特特性和相关挑战。我们提供了对经典结果的广泛调查，以及专门关注联邦设置的最新工作。最后，我们列出了一些值得未来研究的未决问题。为这些问题提供解决方案需要广泛的研究团体的跨学科努力。

**致谢。**我们感谢Jeffrey Li和Mikhail Khodak的有益讨论和评论。这项工作由美国国防部高级研究计划局FA875017C0141支持部分，美国国家科学基金会资助IIS1705121 IIS1838017，大川格兰特，一个谷歌教师奖，一个Amazon Web服务奖项,摩根大通人工智能研究教师奖,卡内基博世研究所研究奖和CONIX研究中心跳六个中心之一，由DARPA赞助的半导体研究公司\(SRC\)项目。在本材料中表达的任何意见、发现、结论或建议都是作者的观点，并不一定反映DARPA、国家科学基金会或任何其他资助机构的观点。

