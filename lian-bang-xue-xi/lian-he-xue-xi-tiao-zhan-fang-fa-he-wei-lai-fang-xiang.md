# 联合学习：挑战、方法和未来方向

联合学习:挑战、方法和未来方向

## 摘要

联邦学习包括在远程设备或竖井数据中心\(如移动电话或医院\)上训练统计模型，同时保持数据本地化。在异构和潜在的大规模网络中的训练引入了新的挑战，需要从根本上背离大规模机器学习、分布式优化和隐私保护数据分析的标准方法。在这篇文章中，我们讨论了联邦学习的独特特征和挑战，提供了当前方法的广泛概述，并概述了与广泛的研究社区相关的未来工作的几个方向。

### 1 引言

移动电话、可穿戴设备和自动驾驶汽车只是现代分布式网络中的一小部分，每天都会产生大量数据。由于这些设备不断增长的计算能力——加上对传输私人信息的关注——本地存储数据和将网络计算推向边缘越来越有吸引力。

边缘计算的概念并不新鲜。事实上，跨分布式、低功耗设备计算简单查询是一个长达数十年的研究领域，已经在传感器网络查询处理、边缘计算和雾计算的范围内进行了探索\[12,29,40,49,74\]。最近的研究也考虑了集中训练机器学习模型，但在本地服务和存储它们;例如，这是移动用户建模和个性化的常用方法\[60,90\]。

然而，随着分布式网络中设备的存储和计算能力的增长，可以利用每个设备上增强的本地资源。这导致了人们对联邦学习的兴趣不断增长\[75\]，该学习探索直接在远程设备上训练统计模型\[1\]。正如我们在本文中讨论的，在这样的环境中学习与传统的分布式环境有很大的不同——需要隐私、大规模机器学习和分布式优化等领域的基本进展，并在不同领域的交叉领域提出了新问题，如机器学习和系统\[91\]。

![image-20210415170935044](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper2/figure-1.png)

图1：手机下一个单词预测任务的联合学习应用示例。为了保护文本数据的隐私并减少网络上的压力，我们寻求以分布式方式训练预测器，而不是将原始数据发送到中央服务器。在这种设置中，远程设备定期与中央服务器通信，以学习全局模型。在每一轮通信中，选定的手机的一个子集对其分布不同的用户数据进行本地训练，并将这些本地更新发送到服务器。合并更新之后，服务器然后将新的全局模型发送回设备的另一个子集。这种迭代训练过程在网络中持续进行，直到达到收敛或满足某个停止准则。

联邦学习方法已被主要的服务提供商部署\[11,124\]，并在支持隐私敏感的应用程序中发挥了关键作用，这些应用程序的训练数据分布在边缘\[例如。， 5, 46, 51, 89, 105, 127, 139\]。潜在的应用包括：情感学习，语义定位，或手机用户的活动；适应自动驾驶汽车中的行人行为；以及预测可穿戴设备引发的心脏病等健康事件\[6,52,84\]。下面我们讨论几个联邦学习的规范应用：

* **智能手机。**通过在一个巨大的手机池学习用户行为，统计模型可以为下一个词预测、人脸检测和语音识别等应用提供动力\[46,89\]。然而，用户可能不愿意分享他们的数据，以保护他们的个人隐私或节省他们手机的有限的带宽/电池电力。联邦学习有潜力在智能手机上启用预测功能，而不会减少用户体验或泄露私人信息。图1描述了一个这样的应用程序，在这个应用程序中，我们的目标是基于用户的历史文本数据\[46\]在大规模移动电话网络中学习下一个单词预测器。
* **组织。**组织或机构也可以被视为联合学习环境中的“设备”。例如，医院是一些组织，它们包含大量用于预测性医疗保健的患者数据。然而，医院在运营中有严格的隐私惯例，可能会面临法律、行政或道德方面的限制，要求数据保留在本地。联邦学习是\[52\]这些应用程序的一个有前途的解决方案，因为它可以减少网络的压力，并允许各种设备/组织之间的私人学习。
* **物联网。**现代物联网网络，如可穿戴设备、自动驾驶汽车或智能家居，可能包含大量传感器，使它们能够实时收集、反应和适应传入数据。例如，一个自动驾驶车队可能需要最新的交通，建筑或行人行为模型来安全操作。然而，由于数据的私有性质和每个设备的有限连接，在这些场景中构建聚合模型可能很困难。联邦学习方法可以帮助训练模型，有效地适应这些系统中的变化，同时保持用户隐私\[84,98\]。

### 1.1 问题公式化

规范联邦学习问题涉及从存储在数千万到数百万远程设备上的数据中学习单个的、全局的统计模型。我们的目标是在设备生成的数据在本地存储和处理，只有中间更新定期与中央服务器通信的约束下学习这个模型。特别是，目标通常是最小化以下目标函数：

$$
\mathop{min}\limits_{w}F(w),\ where\ F(w):=\sum\limits_{k=1}^mp_kF_k(w)
$$

其中，m为设备总数，pk≥0，∑kpk= 1, Fkis为第k个设备的局部目标函数。局部目标函数通常定义为局部数据的经验风险，即Fk\(w\) =1 nk∑nk jk=1fjk\(w;xjk,yjk\)，其中nkis为局部可用的样本数。用户定义术语pkk指定每个设备的相对影响，两个自然设置pk=1或pk=nk n，其中n =∑knkis为样本总数。我们将在整篇文章中引用问题\(1\)，但是，正如下面所讨论的，我们注意到其他目标或建模方法可能是适当的，这取决于感兴趣的应用程序。

### 1.2 核心挑战

接下来，我们将描述与解决\(1\)中提出的分布式优化问题相关的四个核心挑战。这些挑战使联邦设置不同于其他经典问题，如数据中心设置中的分布式学习或传统的私有数据分析。

**挑战1：昂贵的通讯费用。**在联邦网络中，通信是一个关键的瓶颈，再加上发送原始数据时的隐私问题，使得在每个设备上生成的数据必须保持在本地。事实上，联邦网络可能由大量设备组成，例如数百万部智能手机，网络中的通信可能比本地计算慢许多个数量级\[50,115\]。为了适应数据模型生成的联合网络设备，因此有必要开发communication-efficient迭代方法发送小消息或模型更新训练过程的一部分，而不是通过网络发送整个数据集。要在这种情况下进一步减少通信，需要考虑的两个关键方面是：\(i\)减少通信轮的总数，或\(ii\)减少每轮传输信息的大小。

**挑战2：系统异构性。**联邦网络中每个设备的存储、计算和通信能力可能因硬件\(CPU、内存\)、网络连接性\(3G、4G、5G、wifi\)和电源\(电池电量\)的不同而不同。此外，每个设备上的网络大小和系统相关的限制通常导致只有一小部分设备同时处于活动状态，例如，在一个百万设备的网络\[11\]中有数百个活动设备。每个设备也可能是不可靠的，活跃设备在给定迭代中由于连接或能量限制而退出的情况并不罕见。这些系统级的特征极大地加剧了诸如掉队缓解和容错等挑战。因此，开发和分析的联邦学习方法必须：\(i\)预期低参与度，\(ii\)容忍异构硬件，以及\(iii\)对网络中的丢弃设备具有鲁棒性。

**挑战3：统计上的异质性。**设备经常以不同的方式在网络上生成和收集数据，例如，移动电话用户在下一个单词预测任务的上下文中使用不同的语言。此外，设备之间的数据点数量可能会有很大的差异，并且可能存在一个捕获设备及其相关分布之间的关系的底层结构。这种数据生成范式违反了分布式优化中经常使用的独立和同分布\(I.I.D.\)假设，增加了掉线的可能性，并可能增加建模、分析和评估方面的复杂性。的确，虽然\(1\)中的规范联邦学习问题的目标是学习单个全局模型，但也存在其他替代方法，如通过多任务学习框架\[cf.\]同时学习不同的局部模型。106\]。在这方面，联邦学习和元学习的主要方法之间也有密切的联系\[64\]。多任务和元学习视角都支持个性化或设备特定的建模，这通常是处理数据统计异质性的更自然的方法。

**挑战四：隐私问题。**最后，隐私通常是联邦学习应用程序的主要关注点。联邦学习通过共享模型更新，例如梯度信息，而不是原始数据，向保护每个设备上生成的数据迈出了一步\[17,31,33\]。然而，在整个训练过程中，模型更新的通信仍然可以向第三方或中央服务器披露敏感信息\[76\]。虽然最近的方法旨在使用安全多方计算或差分隐私等工具增强联邦学习的隐私性，但这些方法通常以降低模型性能或系统效率为代价提供隐私。从理论和经验上理解和平衡这些权衡，是实现私有联合学习系统的一个相当大的挑战。

本文的其余部分组织如下。在第2节中，我们将介绍以前和当前的工作，这些工作旨在解决所讨论的联邦学习的四个挑战。在第三部分，我们概述了未来研究的几个有希望的方向。

## 2 目前以及相关工作的调查

联邦学习的挑战乍一看类似于隐私、大规模机器学习和分布式优化等领域的经典问题。例如，在机器学习、优化和信号处理领域，已经提出了许多方法来解决昂贵的通信。然而，这些方法通常不能完全处理联邦网络的规模，更不用说系统和统计异构性的挑战了。同样，虽然隐私是许多机器学习应用程序的一个重要方面，但由于数据的统计变化，联邦学习的隐私保护方法很难严格地断言，由于每个设备上的系统限制以及跨潜在的大规模网络，实现起来可能会更加困难。在本节中，我们将更详细地探讨第1节中提出的挑战，包括对经典结果的讨论以及专门关注联邦学习的最新工作。

![image-20210415173437293](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper2/figure-2.png)

图2:左边:分布式\(小批量\)SGD。每个设备k局部计算从一小批数据点的梯度来近似$\nabla F\_k\(w\)$，并将聚合的小批更新应用于服务器上。右图:本地更新方案。每个设备立即应用本地更新，例如，梯度，在他们被计算和服务器执行一个全局聚合后，可变数量的本地更新。本地更新方案可以通过在本地执行额外的工作来减少通信

### 2.1 通信效率

在为联邦网络开发方法时，通信是需要考虑的一个关键瓶颈。虽然对通信高效的分布式学习方法进行完整的回顾超出了本文的范围，但我们指出了几个主要的方向，我们将其分为\(1\)本地更新方法，\(2\)压缩方案，\(3\)分散训练。

#### 2.1.1 本地更新

小批量优化方法将经典随机方法扩展到一次处理多个数据点，已成为数据中心环境中分布式机器学习的流行范式\[28,88,96,102,103\]。然而，在实践中，它们的灵活性被证明是有限的，无法适应最大限度地利用分布式数据处理的通信-计算权衡\[107,108\]。为此，最近提出了几种方法来提高分布式环境下的通信效率，方法是允许在每个通信轮上并行地在每台机器上应用可变数量的本地更新，使计算量相对于通信量更加灵活。对于凸目标，分布式局部更新原始对偶方法已经成为解决这类问题的一种流行方法\[54,62,72,107,128\]。这些方法利用二元结构，有效地将全局目标分解为子问题，并在每一轮通信中并行解决。一些分布式的局部更新原始方法也被提出，它们的额外好处是适用于非凸目标\[93,136\]。这些方法在实践中大大提高了性能，与传统的小批处理方法或分布式方法\(如ADMM\[14\]\)相比，在真实的数据中心环境中，这些方法可以实现数量级的加速。我们在图2中直观地说明了本地更新方法。

在联邦设置中，允许灵活的本地更新和低客户参与的优化方法已经成为事实上的解决方案\[65,75,106\]。联邦学习最常用的方法是联邦平均法\(federingaveraging, FedAvg\)\[75\]，这是一种基于对原始问题的局部随机梯度下降\(local stochastic gradient descent, SGD\)更新的平均方法。FedAvg在经验上表现得很好，特别是对于非凸问题，但它没有收敛性保证，并且在实际设置中，当数据是异构的时，可能会产生分歧\[65\]。我们将在2.3.2节中更详细地讨论处理这种统计异质性的方法。

![image-20210415174258588](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper2/figure-3.png)

图3：集中式与分散式拓扑。在典型的联邦学习设置中，作为本文的重点，我们假设一个星型网络\(左\)，其中服务器连接所有远程设备。当与服务器的通信成为瓶颈时，分散式拓扑\(右\)是一个潜在的替代方案。

