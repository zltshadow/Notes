# index

原文：[联邦学习系统的调查:数据隐私和保护的愿景、炒作和现实](https://arxiv.org/abs/1907.09693)

## 摘要

联邦学习在实现不同组织间机器学习模型在隐私约束下的协同训练方面一直是一个热门研究课题。随着研究人员试图用不同的隐私保护方法支持更多的机器学习模型，在开发系统和基础设施时需要简化各种联邦学习算法的开发。与深度学习系统\(如PyTorch和TensorFlow\)类似，联邦学习系统\(fls\)同样重要，并面临来自有效性、效率和隐私等各个方面的挑战。在这次调查中，我们对联邦学习系统进行了全面的回顾。为了实现顺畅的流程并指导未来的研究，我们引入了联邦学习系统的定义并分析了系统的组成部分。此外，我们还从数据分布、机器学习模型、隐私机制、通信架构、联邦规模和联邦动机等6个方面对联邦学习系统进行了全面的分类。如我们的案例研究中所示，分类可以帮助设计联邦学习系统。通过系统总结现有的联邦学习系统，我们提出了设计因素、案例研究和未来的研究机会。

## 1 引言

许多机器学习算法都需要大量数据，而实际上，在隐私限制的保护下，数据分散在不同的组织中。由于这些因素，联邦学习\(FL\)\[146, 225, 100\]已经成为机器学习的一个热门研究课题。例如，不同医院的数据相互隔离，成为“数据孤岛”。由于每个数据岛在规模和近似真实分布方面都有限制，单个医院可能无法训练出对特定任务具有良好预测精度的高质量模型。理想情况下，如果医院能够联合它们的数据，协同训练一个机器学习模型，它们将受益更多。然而，由于各种政策和法规，这些数据不能简单地在医院之间共享。这种“数据孤岛”的现象在金融、政府、供应链等许多领域都很常见。《通用数据保护条例》\(GDPR\)\[11\]等政策规定了不同组织之间的数据共享规则。因此，在遵循政策法规保护隐私的同时，开发一个具有良好预测准确性的联邦学习系统是一项具有挑战性的工作。

最近，许多人致力于实现联邦学习算法，以支持有效的机器学习模型。具体来说，研究人员试图通过不同的隐私保护方法支持更多的机器学习模型，包括深度神经网络\(NNs\)\[136,233,26,176, 146\]，梯度增强决策树\(gbdt\)\[237,46,120\]，逻辑回归\[159,43\]和支持向量机\(svm\)\[188\]。例如，Nikolaenko等\[159\]和Chen等人\[43\]提出采用基于线性回归的方法进行FL。Hardy等人\[87\]实现了一个FL框架来训练逻辑回归模型。由于gbdt近年来非常成功\[40,218\]，赵等人\[237\]，Cheng等人\[46\]，Li等人\[120\]也提出了相应的联邦学习系统\(Federated Learning Systems, FLSs\)。另一种流行的决策树集成方法，如随机森林，也被扩展到支持隐私保护\[170\]，这是支持FL的重要一步。此外，有许多基于神经网络的fls。谷歌提出了一种可扩展的生产系统，可以使数千万设备训练深度神经网络\[26\]。Y urochkin等人\[233\]利用贝叶斯非参数机制开发了神经网络的概率FL框架。有几种方法尝试将外语学习与机器学习技术相结合，如多任务学习和迁移学习。Smith等人\[188\]将FL与多任务学习结合起来，允许多方完成单独的任务。为了解决标签信息只存在于一方的情况，Yang等人\[225\]采用迁移学习来协作学习模型。

在联邦环境下自定义机器学习算法的研究中，我们已经确定了一些常用的方法和方法。以提供隐私保障的方法为例。一种常见的方法是使用加密技术\[25\]，如安全多方计算\[151\]和同态加密\[87\]。另一种流行的方法是差分隐私\[237\]，它在模型参数中添加噪声以保护个人记录。例如，谷歌的FLS\[25\]同时采用了安全聚合和差异隐私保护，增强了隐私保护。

由于构建FL算法有常见的方法和构建块，因此开发系统和基础设施来简化各种FL算法的开发是有意义的。系统和基础设施允许算法开发人员重用公共构建块，避免每次从头构建算法。类似于深度学习系统,如PyTorch\(166、167\)和TensorFlow\[8\],促进深度学习算法的发展,FLSs对FL的成功同样重要。然而,建设一个成功的FLS的挑战,这需要考虑多个方面如有效性、效率、隐私和自主权。

在本文中，我们从系统的角度对现有的工作流系统进行了综述。首先，我们展示FLSs的定义，并将其与传统联邦系统进行比较。其次，分析了系统的组成部分，包括系统的参与者、管理人员和计算通信框架。第三，从数据分布、机器学习模型、隐私机制、通信架构、联邦规模和联邦动机六个方面对fls进行了分类。这些方面可以指导作为公共构建块和系统抽象的FLS的设计。第四，在这些方面的基础上，系统总结了现有的研究成果，可以用于指导FLSs的设计。最后，为了使FL更加实用和强大，我们提出了未来的研究方向。我们相信系统和基础设施对于FL的成功至关重要。在有效性、效率、隐私和自治方面，还需要进行更多的工作来解决系统研究问题。

### 1.1 相关调查

有一些关于滤过性滤过性的调查。Yang等人\[225\]撰写的一份开创性的调查报告介绍了FL的基础和概念，并进一步提出了一个全面的安全FL框架。后来微众银行\[215\]发表了白皮书，介绍了FL的背景和相关工作，最重要的是提出了建立本地和全球标准、构建用例、形成行业数据联盟等发展路线图。本文主要针对相对较少的一方，通常是企业数据所有者。Li等人\[124\]总结了FL在移动和边缘设备大规模网络中的挑战和未来发展方向。最近，Kaiouz等\[100\]从不同的研究课题对FL的特点和挑战进行了全面的描述。然而，他们主要关注跨设备FL，其中的参与者是大量的移动或物联网设备。最近，另一项调查\[12\]总结了联邦学习的平台、协议和应用。一些调查只关注联邦学习的一个方面。例如，Lim等人\[129\]针对移动边缘计算进行了一项FL调查，而\[142\]主要关注联邦学习面临的威胁。

### 1.2 我们的贡献

据我们所知，目前缺乏对FLSs现有系统和基础设施的回顾，也缺乏对创建FLSs的关注\(类似于深度学习领域蓬勃发展的系统研究\)。与以往的研究相比，本文的主要贡献如下。\(1\)我们的调查是第一次从系统的角度对FL进行全面的分析，包括系统组成、分类、总结、设计和愿景。\(2\)我们从数据分布、机器学习模型、隐私机制、通信体系结构、联邦规模、联邦动机等6个方面对fls进行了综合分类，可作为fls的公共构建块和系统抽象。\(3\)我们对现有的典型研究和最新研究成果按研究领域进行总结，方便研究人员和开发人员参考。\(4\)我们提出了成功的FLS的设计因素，并对每个场景进行了全面的审查。\(5\)我们提出了未来FLSs的研究方向和挑战。本文的其余部分组织如下。

在第2节中，我们将介绍FLS的概念，并将其与传统联邦系统进行比较。在第3节中，我们介绍了FLS的系统组成部分。在第4节中，我们提出了从6个方面来分类fls。在第5节中，我们总结了关于FL的现有研究和系统，然后在第6节中介绍了FL的设计因素和解决方案。最后，我们在第8节中提出未来可能的FL方向，并在第9节中总结我们的论文。

## 2 联邦学习系统概述

### 2.1 背景

近年来，数据泄露严重威胁着用户的数据隐私。在2019年的一次重大泄露中，超过5.4亿Facebook用户的记录被泄露在亚马逊的云\[3\]上。2019年，美国海关和边境保护局宣布了一项数据泄露事件，数万张旅行者的照片被泄露。

随着数据泄露成为人们关注的主要问题，越来越多的政府建立了保护用户数据的法规，如欧盟的GDPR\[203\]，新加坡的PDPA\[47\]，美国的CCPA\[1\]。对于公司来说，违反这些政策的代价是相当高的。2016年，60万名司机的个人信息被泄露，优步不得不支付1.48亿美元以了结调查。SingHealth因违反PDPA\[5\]被新加坡政府罚款75万美元。谷歌因违反GDPR\[4\]被罚款5700万美元，这是截至2020年3月18日根据欧盟隐私法开出的最高罚单。

在上述情况下，联邦学习，即不交换用户原始数据的协作学习，越来越受到人们的关注。机器学习，特别是深度学习，近年来再次受到人们的关注，而联邦与机器学习的结合则是一个新的研究热点。

### 2.2 定义

FL使多方在不交换本地数据的情况下共同训练机器学习模型。它涵盖了多个研究领域的技术，如分布式系统、机器学习和隐私。这里我们给出了fls的正式定义。

我们假设有N个不同的值，每个值记为Ti，其中i∈\[1,N\]。我们用Di表示Ti的数据。对于非联邦场景，每一方Ti仅使用其本地数据Di来训练机器学习模型Mi, Mi的预测精度表示为Pi。在联邦场景中，各方共同训练一个模型$$M_f$$，各方Ti根据其具体的隐私限制保护其数据Di。$$M_f$$的预测精度记为$$P_f$$。那么，对于一个有效的FLS，存在i∈\[1,N\]使得$$P_f>P_i$$。

注意,在上面的定义中,我们只要求存在任何一方可以从FL实现更高的模型质量。尽管一方可能不会从FL得到一个更好的模型,他们仍可能加入联盟,使与其他各方达成协议要求的其他激励机制\(例如,金钱\)。

### 2.3 与传统联邦系统比较

联邦的概念可以在现实世界中找到，比如商业和体育。联邦的主要特点是合作。联邦不仅在社会中普遍出现，而且在计算中也起着重要的作用。在计算机科学中，联邦计算系统在不同的背景下一直是一个有吸引力的研究领域。

1990年前后，有很多关于联邦数据库系统\(fdbs\)的研究\[185\]。FDBS是一组相互合作的自治数据库。正如之前的研究指出的\[185\]，FDBS的三个重要组成部分是自主性、异质性和分布性。

* 自主性。参与FDBS的数据库系统\(DBS\)是自治的，这意味着它处于独立和独立的控制之下。双方仍然可以在没有FDBS的情况下管理数据。
* 异质性。在FDBS中，数据库管理系统可以是不同的。例如，差异可能在于数据结构、查询语言、系统软件需求和通信能力。
* 分布性。在FDBS建立之前，由于存在多个dbs，不同dbs的数据分布可能不同。一个数据记录可以水平或垂直地划分到不同的dbs中，也可以在多个dbs中重复，以提高可靠性。

最近，随着云计算的发展，对联邦云计算进行了许多研究\[113\]。联合云\(FC\)是多个外部和内部云计算服务的部署和管理。通过将部分外包给成本效率更高的地区，云联合概念可以进一步使成本降低。资源迁移和资源冗余是联邦云的两个基本特征\[113\]。首先，资源可以从一个云提供商转移到另一个云提供商。迁移可以实现资源的重新定位。第二，冗余允许在不同的领域并发使用类似的服务特性。例如，可以根据相同的计算逻辑在不同的提供者处对数据进行分区和处理。总的来说，不同资源的调度是联邦云系统设计中的一个关键因素。

fls和传统联邦系统之间有一些相似之处和不同点。首先，联邦的概念仍然适用。其共同和基本的理念是多独立主体的合作。因此，考虑当事人之间的异质性和自治性的观点仍然可以应用于fls。其次，分布式系统设计中的一些因素对fls仍然很重要。例如，在各方之间共享数据的方式可能影响系统的效率。由于差异，这些联邦系统对协作和约束的重视程度不同。fdbs关注的是分布式数据的管理，FCs关注的是资源的调度，而fls关注的是多方的安全计算。FLSs带来了新的挑战，如分布式训练的算法设计和隐私限制下的数据保护。

图1显示了这三个研究领域每年的论文数量。我们在谷歌学术中搜索关键词“federated database”、“federated cloud”、“federated learning”进行论文统计。虽然联邦数据库在30年前就被提出了，但近年来仍有约400篇论文提到了联邦数据库。联邦云的流行度在一开始比联邦数据库增长得更快，但在最近几年似乎有所下降，这可能是因为云计算变得更加成熟，联邦的动机也在减弱。对于FL来说，相关论文的数量正在迅速增加，去年已经达到约4400篇。如今，“数据岛”现象是普遍且日益成为机器学习中的一个重要问题。此外，公众对隐私的关注和社会意识也在不断提高。因此，我们预计FL的受欢迎程度将持续增加，至少5年，直到可能有成熟的fls。

![image-20210507104204412](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper5/figure-1.png)

图1：关于“联邦数据库”、“联邦云”和“联邦学习”的相关论文数量

## 3 系统组件

FLS中有三个主要组件：当事人\(例如，客户端\)、管理者\(例如，服务器\)和用于训练机器学习模型的通信计算框架。

### 3.1 当事人

在fls中，各当事人是数据所有者，也是FL的受益者。他们可以是组织或移动设备，分别命名为跨竖井或跨设备场景\[100\]。我们考虑影响fls设计的各方的以下特性。

第一，各方的硬件能力如何？硬件容量包括计算能力和存储能力。如果参与者是手机，则容量较弱，参与者无法进行大量计算和训练大型模型。例如，Wang等人\[211\]考虑FL中的资源约束设置。他们设计了一个包括资源预算的目标，并提出了一种确定本地更新轮数的算法。

第二，各方的规模和稳定性如何？对于组织来说，与移动设备相比，规模相对较小。此外，跨竖井场景的稳定性优于跨设备场景。因此，在跨竖井场景中，我们可以期望每一方能够在整个联邦进程中不断地执行计算和通信任务，这是许多研究中常见的场景\[120,46,188\]。如果双方是移动设备，系统需要处理\[26\]连接丢失等可能的问题。此外，由于设备的数量可能非常大\(例如，数百万\)，在FL中假定所有设备都参与每一轮是不现实的。广泛使用的方法是在每一轮中选择一部分设备进行计算\[146,26\]。

最后，各方之间的数据分布是什么？通常，无论跨设备还是跨竖井场景，非iid\(相同且独立分布\)数据分布都被认为是联邦学习中一个实用且具有挑战性的设置\[100\]，在最近的工作中\[120,233,127,208\]的实验中得到了评估。这种非iid数据分布在各组织之间可能更为明显。例如，银行和保险公司可以使用FL来提高他们的预测5例如，一个人是否可以偿还贷款，这个人是否会购买保险产品\)，而这些组织的功能甚至可以有很大的差异。迁移学习\[165\]、元学习\[65\]和多任务学习\[175\]的技术可能有助于结合各种各样的参与者的知识。

### 3.2 管理者

在跨设备场景中，管理器通常是一个强大的中央服务器。负责对全局机器学习模型进行培训，管理各方与服务器之间的通信。服务器的稳定性和可靠性非常重要。一旦服务器不能提供准确的计算结果，FLS可能会产生一个坏的模型。为了解决这些潜在的问题，区块链\[195\]可能是一种提供分散解决方案的技术，以提高系统的可靠性。例如，Kim等人\[109\]利用区块链代替了系统中的中央服务器，区块链允许交换设备更新并为它们提供奖励。

在跨竖井场景中，由于组织被期望拥有强大的机器，管理器也可以是主导FL过程的组织之一。这在垂直FL\[225\]中特别使用，我们将在4.1节中详细介绍。在Liu等人的垂直FL场景中\[136\]，数据的特征在各方之间垂直划分，只有一方拥有标签。拥有标签的一方自然被认为是FL管理器。

一个挑战可能是很难找到一个受信任的服务器或一方作为管理者，特别是在跨竖井场景中。然后，一个完全去中心化的场景可以是一个很好的选择，在那里各方可以直接相互交流，几乎平等地为全球机器学习模型训练做出贡献。在这里，管理器实际上是所有的当事人。这些各方共同设置一个FL任务并部署FLS。Li等人\[120\]提出了一种联邦梯度推进决策树框架，每一方依次训练决策树，最终的模型是所有树的组合。设计一个具有合理通信开销的完全分散的FLS是一个挑战。

### 3.3 通信控制系统框架

在fls中，计算发生在各方和管理器上，而通信发生在各方和管理器之间。通常，计算的目的是为了模型训练，通信的目的是为了交换模型参数。

联邦平均\(Federated Averaging, FedAvg\)\[146\]是2016年提出的一个基本框架，应用广泛，如图2a所示。在每次迭代中，服务器首先将当前全局模型发送给选定的各方。然后，被选方用他们的本地数据更新全局模型。接下来，将更新后的模型发送回服务器。最后，服务器对所有接收到的局部模型进行平均，得到一个新的全局模型。FedAvg重复上述过程，直到达到指定的迭代次数。服务器的全局模型是最终的输出。

FedAvg是一个集中的FL框架，而Li等人提出的SimFL\[124\]则是一个分散的FL框架。在SimFL中，不需要受信任的服务器。在每次迭代中，各方首先更新其本地数据的梯度。然后，渐变被发送到选定的一方。接下来，被选方使用其本地数据和梯度来更新模型。最后，将模型发送给所有其他方。为了确保公平性，并利用来自不同方的数据，每个方都被选中进行相同轮数的模型更新。SimFL重复指定的迭代次数并输出最终的模型。

一个具有挑战性和重要的方向是研究计算和通信代价之间的权衡。具体来说，人们可能想知道收敛速度、两轮通信之间的局部计算迭代和总通信轮之间的关系。最近，Li等人\[127\]研究了FedAvg在非iid数据分布上的收敛性。他们的理论表明，收敛速度与总局部迭代次数\(即两个通信轮之间的局部计算迭代次数乘以总通信轮数\)成反比。

![image-20210507111753280](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper5/figure-2.png)

图2：联邦学习框架

另一个值得注意的方面是，除了模型参数之外，还可能需要更多的信息来进行计算和通信，以满足隐私保证。模型参数容易受到推理攻击，可能暴露训练数据的敏感信息\[186,155,66\]。一种可能的解决方案是安全多方计算\[131,76\]，它使各方能够在他们的输入上联合计算一个功能，同时保持这些输入的私密性。然而，加密的计算开销和发送密钥的通信开销是重要的，可能成为整个FL过程的瓶颈。因此，效率是fls中的一个重要指标，许多人一直致力于减少开销，特别是通信规模\[111,146,183,27,122\]。

## 4 分类

考虑到不同fls的通用系统抽象和构建模块，我们从数据划分、机器学习模型、隐私机制、通信架构、联邦规模和联邦动机6个方面对fls进行了分类。这些方面包括以前的FLSs\[185, 113\]中的公共因素\(如数据划分、通信体系结构\)和FLSs的独特考虑\(如机器学习模型和隐私机制\)。此外，这些方面可以用于指导fls的设计。图3显示了fls分类的摘要。

![image-20210507111936296](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper5/figure-3.png)

图3：联邦学习系统的分类

让我们用一个直观的例子来解释这六个方面。不同地区的医院想要进行FL以提高肺癌预测任务的效率。然后，设计这样一个FLS需要考虑六个方面。

* **数据分区。**我们应该研究病人档案在医院中的分布情况。虽然医院可能有不同的病人，但他们也可能对一个普通病人有不同的认识。因此，我们必须同时利用FL中的非重叠实例和特性。
* **机器学习模型。**我们应该弄清楚应该采用哪种机器学习模型来完成这样的任务。例如，如果我们想对诊断图像执行分类任务，我们可能想在FL中训练一个卷积神经网络。
* **隐私机制。** 我们必须决定使用什么技术来保护隐私。由于病人记录是非常私密的，我们可能必须确保它们不能被交换的梯度和模型推断出来。差分隐私是实现隐私保障的一种选择。
* **通信架构。**我们必须确定通信架构。如果有一个值得信任的服务器，那么它可以是FL中的管理者。否则我们必须采用去中心化设置。
* **联邦规模。**与移动设备上的FL不同，在这种情况下，我们的federation规模相对较小，且稳定性较好。另外，每一方都有相对较大的计算能力，这意味着我们可以在FL过程中容忍更多的计算操作。
* **联邦动机。**我们应该考虑各方鼓励他们参与FL的动机。对于医院来说，一个明确而直接的动机是提高肺癌预测的准确性。然后，FL应实现一个比各方本地训练具有更高精度的模型。

### 4.1 数据分区

根据数据在样本和特征空间上的分布方式，通常可以将fls分为水平fls、垂直fls和混合fls\[225\]。

在水平FL中，不同方的数据集具有相同的特征空间，但在样本空间上很少有交集。这是一种自然的数据分区，特别是在跨设备场景时，不同的用户试图使用FL在同一任务上改进他们的模型性能。而且，大多数FL研究采用水平分区。由于局部数据具有相同的特征空间，因此双方可以使用具有相同模型体系结构的局部数据来训练局部模型。通过对所有局部模型求平均值，可以简单地更新全局模型。水平联邦学习的一个基本和流行的框架是FedAvg，如图2所示。唤醒词识别\[114\]，如“Hey Siri”和“OK Google”，是水平份去的典型应用，因为每个用户用不同的声音说同一个句子。

在垂直FL中，不同方的数据集具有相同或相似的样本空间，但特征空间不同。对于垂直FLS，通常采用实体对齐技术\[224,49\]来收集各方的重叠样本。然后利用重叠数据用加密方法训练机器学习模型。Cheng等人提出了一种无损的垂直FLS，使各方能够协作训练梯度推进决策树。他们使用隐私保护实体对齐来寻找双方之间的共同用户，并用其梯度来联合训练决策树。政府机构之间的合作可以看作是一种垂直划分的情况。假设税务部门需要居民住房数据来制定税收政策，居民住房数据存储在住房部门。同时，住房部门也需要居民的税务信息，这些信息由税务部门保存，以调整居民的住房政策。这两个部门共享相同的样本空间\(即国家的所有居民\)，但每个部门只有一部分特征\(如住房或税务相关的个人数据\)。

在其他许多应用中，现有的fls大多集中在一种分区上，而各方之间的数据分区可能是水平分区和垂直分区的混合。我们以癌症诊断系统为例。一些医院希望建立一个用于癌症诊断的FLS，但每家医院都有不同的患者以及不同种类的医疗检查结果。迁移学习\[165\]是一种可能的解决方案。Liu等人\[136\]提出了一种安全的联邦迁移学习系统，该系统可以使用公共实例学习各方特征之间的表示。

### 4.2 机器学习模型

由于FL是用来解决机器学习问题的，所以双方通常希望在特定的任务上训练一个最先进的机器学习模型。在开发新模型或重新设计现有模型以适应联邦环境方面已经做出了许多努力。在这里，我们考虑目前广泛使用的模型。目前最流行的机器学习模型是神经网络\(NN\)，它在图像分类和单词预测等许多任务中取得了最先进的结果\[112,194\]。基于随机梯度下降的联邦学习研究有很多\[146,208,26\]，可以用来训练神经网络。

另一种广泛使用的模型是决策树，与网络相比，决策树训练效率高，易于解释。基于树的FLS是专为单个或多个决策树\(如梯度推进决策树\(gbdt\)和随机森林\)的训练而设计的。gbdt是近年来特别流行的一种方法，它在许多分类和回归任务中都有很好的性能。Li等人\[120\]和Cheng等人\[46\]分别对水平和垂直分割数据上的gbdt提出了fls。

除了神经网络和树，线性模型\(如线性回归，逻辑回归，支持向量机\)是经典和易于使用的模型。有一些非常完善的线性回归和逻辑回归系统\[159,87\]。与其他复杂模型\(如nn\)相比，这些线性模型基本上容易学习。

目前，许多基于随机梯度下降的FL框架\[146,110,211,123\]被提出，这是神经网络和逻辑回归等许多模型的典型优化算法。然而，为了提高FL的有效性，我们可能需要利用模型架构\[208\]。由于FLS的研究还处于初级阶段，FLS在更好地支持先进的模型方面还存在差距。

### 4.3 隐私机制

虽然在FL中没有公开本地数据，但交换的模型参数仍然可能泄漏有关数据的敏感信息。针对机器学习模型的攻击有很多\[205,66,31,186,155,148\]，如模型反转攻击\[66\]和隶属度推理攻击\[186\]，这些攻击可以通过访问模型来潜在地推断原始数据。此外，目前有许多隐私保护机制，如差分隐私\[58\]和k-匿名\[60\]，它们提供了不同的隐私保障。调查总结了现有隐私机制的特点\[204\]。在这里，我们介绍了当前FLSs中用于数据保护的两种主要方法：加密方法和差分隐私。

密码方法如同态加密\[16,87,28,34,82,173,174,232,234,133\]和安全多方计算\(SMC\)\[184, 38, 24, 55, 25, 118, 18, 68, 107, 206, 41, 72\]被广泛应用于隐私保护机器学习算法中。基本上，双方在发送消息之前必须对消息进行加密，对加密的消息进行操作，并对加密的输出进行解密，以获得最终结果。应用上述方法，通常可以很好地保护fls的用户隐私\[103,229,105,162,230\]。例如，SMC\[76\]保证所有各方除了输出之外不能学到任何东西。然而，SMC容易受到推理攻击。此外，由于额外的加密和解密操作，这样的系统承受着极高的计算开销。

差分隐私\[58,59\]保证了单个记录不会对函数的输出产生太大影响。许多研究采用差分隐私\[37,19,9,220,237,93,121,199,239,128\]来保护数据隐私，以确保当事人不知道个人记录是否参与了学习。通过向数据或模型参数中注入随机噪声\[9,121,189\]，差分隐私为单个记录提供了统计隐私保证，并防止对模型的推理攻击。由于学习过程中的噪声，这类系统往往产生不太准确的模型。

需要注意的是，上述方法是相互独立的，一个FLS可以采用多种方法来增强隐私保障\[77,223\]。还有其他保护用户隐私的方法。一种有趣的基于硬件的方法是使用可信执行环境\(TEE\)，如Intel SGX处理器\[177,163\]，它可以保证加载在其中的代码和数据受到保护。这种环境可以在中央服务器内部使用，以增加其可信度。

虽然大多数现有的fls采用加密技术或差异隐私来实现良好的隐私保证，但这些方法的局限性似乎难以克服。在尽量减少这些方法带来的副作用的同时，寻找保护数据隐私和灵活的隐私要求的新方法也可能是一个很好的选择。例如Liu等\[136\]采用了一个较弱的安全模型\[56\]，使得系统更加实用。

与隐私级别相关，威胁模型在fls中也有所不同\[142\]。攻击可以来自FL过程的任何阶段，包括输入、学习过程和学习模型。

* **输入** 恶意方可以对FL进行数据投毒攻击\[42,115,13\]。例如，恶意方可以修改特定类训练样本的标签，使学习到的模型在该类上表现较差。
* **学习过程** 在学习过程中，各方可以进行模型投毒攻击\[17,221\]，上传设计好的模型参数。与数据投毒攻击一样，由于局部更新中毒，全局模型的精度可能非常低。除了模型投毒攻击外，拜占庭错误\[33,23,45,192\]也是分布式学习中常见的问题，在这种情况下，各方可能会任意行为，并上传随机更新。
* **学习模式** 如果被学习的模型被发表，就可以对其进行推理攻击\[66,186,148,155\]。服务器可以从交换的模型参数中推断出有关训练数据的敏感信息。例如，隶属关系推理攻击\[186,155\]可以推断一个特定的数据记录是否被用于训练。注意，推理攻击也可能由FL管理器在学习过程中进行，他可以访问各方的本地更新。

### 4.4 通信架构

在fls中有两种主要的通信方式：集中设计和分散设计。在集中式设计中，数据流通常是非对称的，这意味着管理者从各方聚集信息\(例如，本地模型\)并发回训练结果\[26\]。全局模型上的参数更新总是在这个管理器中完成。管理器和本地方之间的通信可以是同步的\[146\]或异步的\[222,190\]。在分散式设计中，通信在各方之间进行\[237,120\]，每一方都能够直接更新全局参数。

Google键盘\[86\]是集中式架构的一个例子。服务器从用户的设备收集本地模型更新，并训练一个全局模型，然后将其发送回用户进行推断，如图2a所示。可扩展性和稳定性是集中式FL系统设计的两个重要因素。集中式设计在现有研究中得到了广泛的应用，但在某些方面，集中式设计更受青睐，因为信息集中在一台服务器上可能会带来潜在的风险或不公平。最近，区块链\[242\]是一个流行的去中心化平台。为FL设计一个去中心化的系统仍然是一个挑战，在学习过程中，各方在通信方面几乎是平等的，不需要信任的服务器。医院间分散式癌症诊断系统就是分散式架构的一个例子。每家医院共享使用患者数据训练的模型，并获得用于\[29\]诊断的全局模型。在去中心化设计中，主要的挑战是很难设计一个协议，以合理的通信开销几乎公平地对待每个成员。由于没有中央服务器，培训是在各方进行的，所以一方可能需要向所有其他方收集信息，各方的沟通开销自然与各方的数量成正比。

### 4.5 联邦规模

根据联邦的规模，可以将fls分为两种典型类型：跨竖井fls和跨设备fls\[100\]。它们之间的区别在于参与者的数量和每个参与者中存储的数据量。

在跨竖井FLS中，当事人是组织或数据中心。通常有相对较少的参与者，每个参与者都有相对较大的数据量和计算能力。例如，亚马逊希望通过训练从世界各地数百个数据中心收集的购物数据来为用户推荐商品。每个数据中心都拥有庞大的数据量和充足的计算资源。此类FLS面临的一个挑战是如何在隐私模型约束下有效地将计算分发到数据中心\[243\]。

而在跨设备的FLS中，参与者的数量相对较大，每个参与者的数据量和计算能力都相对较小\[210\]。当事人通常是移动设备。谷歌Keyboard\[226\]是跨设备fls的一个例子。谷歌Keyboard的查询建议可以在FL的帮助下改进。考虑到能耗问题，不能要求设备进行复杂的训练任务。在这种情况下，系统应该足够强大，能够管理大量的参与者，并处理可能出现的问题，如设备和服务器之间的连接不稳定。

### 4.6 联邦动机

在实际的FL应用中，个体需要动机来参与到FLS中。动机可以是规章制度或激励措施。公司或组织内部的FL通常是由规章制度驱动的\(例如，公司不同部门的FL\)。但在许多情况下，法规不能强迫当事人提供数据。以谷歌Keyboard\[226\]为例，谷歌不能阻止不提供数据的用户使用谷歌Keyboard。但是那些同意上传输入数据的人可能会获得更高的单词预测精度。这种激励可以鼓励每个用户提供他们的数据，以提高整体模型的性能。然而，如何设计这样一个合理的协议仍然是一个挑战。

激励机制的设计对于FLS的成功至关重要。在区块链\[247,61\]中有一些成功的激励设计案例。系统内的各方可以是合作者，也可以是竞争者。其他的激励设计如\[102,101\]被提出以高质量的数据为FL吸引参与者。我们期望在fls下，博弈论模型\[182,99,154\]及其均衡设计应该被重新审视。即使在谷歌键盘的情况下，用户也需要被激励来参与这个协作学习过程。

