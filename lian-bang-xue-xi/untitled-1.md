# index

原文：[联邦学习的进展和有待解决的问题](https://export.arxiv.org/pdf/1912.04977)

## 摘要

联邦学习\(FL\)是一种机器学习方法，许多客户端\(例如移动设备或整个组织\)在中央服务器\(例如服务提供商\)的编排下协同训练一个模型，同时保持训练数据分散。FL体现了集中数据收集和最小化的原则，可以减轻许多由传统的、集中的机器学习和数据科学方法造成的系统性隐私风险和成本。由于FL研究的爆炸性增长，本文讨论了最近的进展，并提出了广泛的开放式问题和挑战。

## 1 介绍

联邦学习\(FL\)是一种机器学习方法，许多客户端\(例如移动设备或整个组织\)在中央服务器\(例如服务提供商\)的编排下协同训练一个模型，同时保持训练数据分散。它体现了集中收集和数据最小化的原则，可以减轻许多由传统的、集中的机器学习导致的系统性隐私风险和成本。从研究和应用的角度来看，这一领域最近受到了极大的关注。本文描述了联邦学习方法的定义特征和挑战，强调了重要的实践约束和注意事项，并列举了一系列有价值的研究方向。这项工作的目标是突出具有重大理论和实践兴趣的研究问题，并鼓励对可能有重大现实影响的问题的研究。

联邦学习这个术语是由McMahan等人在2016年引入的\[337\]:“我们将我们的方法称为联邦学习，因为学习任务是通过由中央服务器协调的参与设备\(我们称之为客户机\)的松散联邦来解决的。”跨大量通信带宽有限的不可靠设备的不平衡和非iid\(相同和独立分布\)数据分区被引入作为定义方面的挑战。

在联邦学习这个术语出现之前，就已经有了一些重要的相关工作。许多研究团体\(包括密码学、数据库和机器学习\)追求的一个长期目标是分析和学习分布在许多所有者之间的数据，而不暴露这些数据。在加密数据上计算的加密方法始于20世纪80年代早期\[396,492\]，Agrawal和Srikant\[11\]和Vaidya等人\[457\]是早期尝试使用集中式服务器从本地数据中学习并同时保护隐私的例子。相反，即使引入了联邦学习这个术语，我们也没有发现任何一项工作可以直接解决FL的所有挑战。因此，联邦学习这个术语为一组特征、约束和挑战提供了方便的简写，这些特征、约束和挑战经常同时出现在去中心化数据的应用ML问题中，而在去中心化数据中，隐私至关重要。

本文源自于谷歌西雅图办公室于2019年6月17 - 18日举办的联邦学习与分析研讨会。在这次为期两天的活动中，对联邦学习领域中许多开放式挑战进行广泛调查的必要性变得清晰起来。

讨论的许多问题的一个关键属性是，它们本质上是跨学科的——解决这些问题可能不仅需要机器学习，还需要来自分布式优化、密码学、安全、差异隐私、公平、压缩感知、系统、信息理论、统计学等方面的技术。许多最棘手的问题都处在这些领域的交叉点上，因此我们相信，协作将对持续的进展至关重要。这项工作的目标之一是强调这些领域的技术可以结合的方式，提出有趣的可能性和新的挑战。

自从术语联邦学习最初引入的重点是移动和边缘设备应用程序\(337、334\),对FL应用到其他应用程序的兴趣大大增加,其中一些可能只涉及少量的相对可靠的客户,例如多个组织合作训练模型。我们分别将这两个联邦学习方法称为“跨设备”和“跨竖井”。鉴于这些变化，我们提出了一个更广泛的联邦学习定义：

**联邦学习**是一种机器学习方法，在中央服务器或服务提供商的协调下，多个实体\(客户端\)协作解决机器学习问题。每个客户的原始数据存储在本地，不交换或转移;相反,有针对性的更新是狭义的更新，以包含手头特定学习任务所需的最低信息;在数据最小化服务中，尽可能早地执行聚合。我们注意到，这个定义将联邦学习与第2.1节中讨论的完全分散\(点对点\)学习技术区分开来。

虽然隐私保护数据分析的研究已经超过50年，但只有在过去的10年才有大规模的解决方案被广泛部署\(例如\[177,154\]\)。跨设备联邦学习和联邦数据分析正在应用于消费数字产品中。谷歌在Gboard移动键盘\[376,222,491,112,383\]以及Pixel手机\[14\]和Android Messages\[439\]中广泛使用了联邦学习。虽然谷歌是跨设备FL的先驱，但对这种方法的兴趣现在更广泛了，例如:苹果在iOS 13的\[25\]中使用跨设备FL，用于QuickType键盘和“Hey Siri”\[26\]的声音分类器;doc.ai 正在为医学研究开发跨设备的FL解决方案\[149\]，而Snips已经探索了用于热点词检测的跨设备FL\[298\]。

跨竖井应用也被提出或描述在无数领域，包括再保险的金融风险预测\[476\]、药品发现\[179\]、电子健康记录挖掘\[184\]、医疗数据分割\[15,139\]和智能制造\[354\]。

对联邦学习技术不断增长的需求导致了大量的工具和框架的出现。这些包括TensorFlow Federated \[38\]， Federated AI Technology Enabler \[33\]， PySyft \[399\]， Leaf \[35\]， PaddleFL\[36\]和Clara Training Framework \[125\];更多细节请参见附录a。商业数据平台联合联邦学习是由成熟的技术公司以及小型初创公司开发的。

表1对比了跨设备和跨竖井联邦学习与跨一系列轴的传统单数据中心分布式学习。这些特征建立了许多实际联邦学习系统通常必须满足的约束，因此既可以激励联邦学习，也可以告知联邦学习中的开放式挑战。它们将在接下来的章节中详细讨论。

![image-20210426105143687](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper4/table-1.png)

表1：联邦学习算法与数据中心中分布式学习的典型特征\(例如\[150\]\)。跨设备和跨竖井联邦学习是FL领域的两个例子，但并不打算详尽无遗。FL的主要定义特征以粗体突出，但其他特征在决定哪些技术适用时也是至关重要的。

这两种FL的变体被称为代表性和重要的例子，但不同的FL方法可能有这些特征的不同组合。在本文的其余部分，我们考虑跨设备的FL算法，除非另有说明，尽管许多问题也适用于其他FL算法。第2节专门讨论了许多其他变体和应用程序中的一些。

接下来，我们将更详细地考虑跨设备联邦学习，重点关注该技术典型大规模部署中常见的实际方面;Bonawitz等人\[81\]为特定的生产系统提供了更多的细节，包括对特定架构选择和考虑事项的讨论。

### 1.1 跨设备联邦学习算法

本节采用应用透视图，与前一节不同的是，不尝试定义透视图。相反，我们的目标是描述跨设备FL中的一些实际问题，以及它们如何适应更广泛的机器学习开发和部署生态系统。希望为接下来的开放问题提供有用的背景和动机，同时帮助研究人员估计在现实世界系统中部署一种特殊的新方法有多简单。在考虑FL训练过程之前，我们先画一个模型的生命周期草图。

#### 1.1.1 联邦学习模式的生命周期

FL过程通常是由为特定应用程序开发模型的模型工程师驱动的。例如，自然语言处理领域的专家可以开发一个用于虚拟键盘的下一个单词预测模型。图1显示了主要组件和参与者。在高层次上，典型的工作流是：

![image-20210426114546464](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper4/figure-1.png)

图1：经过fl训练的模型的生命周期和联邦学习系统中的各种参与者。第4节从威胁模型的角度重新讨论了该图。

1. **问题识别**：模型工程师识别一个需要用FL解决的问题。
2. **客户端检测**：如果需要，客户端\(例如手机上运行的应用程序\)被检测到本地存储必要的训练数据\(有时间和数量限制\)。在很多情况下，应用程序已经存储了这些数据\(例如，一个短信应用程序必须存储短信，一个照片管理应用程序已经存储照片\)。然而，在某些情况下，可能需要维护额外的数据或元数据，例如用户交互数据，为监督学习任务提供标签。
3. **仿真原型\(可选\)**：模型工程师可以使用代理数据集在FL模拟中对模型架构进行原型化并测试学习超参数。
4. **联邦模型训练**：启动多个联邦训练任务来训练模型的不同变体，或使用不同的优化超参数。
5. **\(联邦\)模型评估**：在任务得到充分训练之后\(通常是几天，如下\)，将对模型进行分析并选择好的候选者。分析可能包括在数据中心的标准数据集上计算的指标，或者联邦评估，其中将模型推到保留的客户端，对本地客户数据进行评估。
6. **部署**：最后，一旦一个好的模型被选中，它将经历一个标准的模型启动过程，包括手动质量保证，实时的A /B测试\(通常是在一些设备上使用新模型，在其他设备上使用上一代模型来比较它们的体内性能\)，以及分段推出\(以便在影响太多用户之前发现和回滚不良行为\)。模型的特定启动过程是由应用程序的所有者设置的，通常与模型如何训练无关。换句话说，这个步骤同样适用于经过联邦学习或传统数据中心方法训练的模型。

FL系统面临的主要实际挑战之一是使上述工作流程尽可能简单，理想地接近ML系统实现集中训练的易用性。虽然本文主要关注联邦训练，但还有许多其他组件，包括联邦分析任务，如模型评估和调试。改进这些是第3.4节的重点。现在，我们更详细地考虑单个FL模型的训练\(上面的第4步\)。

#### 1.1.2 典型的联邦训练过程

我们现在考虑一个FL训练模板，它包含McMahan等人\[337\]的联邦平均算法和许多其他算法；同样，变化是可能的，但这提供了一个共同的起点。

服务器\(服务提供者\)通过重复以下步骤来协调训练过程，直到训练停止\(由监控训练过程的模型工程师决定\)：

1. **客户端选择：**来自一组满足资格要求的客户端的服务器示例。例如，为了避免影响设备的用户，移动电话可能只有在插入、未计量的wi-fi连接和空闲的情况下才会检查到服务器。
2. **广播：**选定的客户端从服务器下载当前的模型权重和一个训练程序\(例如TensorFlow图\[2\]\)。
3. **客户机计算：**每个选定的设备通过执行训练程序本地计算对模型的更新，例如，训练程序可以在本地数据上运行SGD\(如Federated平均化\)。
4. **聚合：**服务器对设备的更新进行聚合。为了提高效率，一旦有足够数量的设备报告了结果，可能会在此时删除掉队的设备。这一阶段也是许多其他技术的集成点，这些技术将在后面讨论，可能包括：用于增加隐私的安全聚合，用于通信效率的聚合的有损压缩，以及用于差异隐私的噪声添加和更新剪辑。
5. **模型更新：**服务器基于从参与当前轮的客户端计算的聚合更新本地更新共享模型。

表2给出了移动设备上典型联邦学习应用程序中涉及的数量的典型数量级。

![image-20210426143501496](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper4/table-2.png)

表2：典型的跨设备联邦学习应用程序的数量级大小。

分离客户机计算、聚合和模型更新阶段并不是联邦学习的严格要求，而且它确实排除了某些算法类，例如异步SGD，在使用其他客户机的更新进行任何聚合之前，每个客户机的更新都立即应用于模型。这种异步方法可能简化系统设计的某些方面，并且从优化的角度来看也是有益的\(尽管这一点还有待讨论\)。然而，上述方法在区分不同研究方向的关注点方面有很大的优势：压缩、差异隐私和安全多方计算的进步可以用于标准原语，如求和或通过去中心化更新的方法，然后与任意优化或分析算法组成，只要这些算法以聚合原语的形式表示。

同样值得强调的是，在两个方面，FL的训练过程不应该影响用户体验。首先，如上所述，尽管模型参数通常在每一轮联邦训练的广播阶段发送到一些设备，但这些模型只是训练过程中短暂的一部分，不用于向用户显示“实时”预测。这是至关重要的，因为训练ML模型是具有挑战性的，而且一个超参数的错误配置可能产生一个做出错误预测的模型。相反，用户可见的模型使用被推迟到模型生命周期的第6步中详细描述的推出过程中。第二，培训本身对用户是不可见的——正如在客户端选择中所描述的，培训不会使设备变慢或耗尽电池，因为它只在设备空闲和连接电源时执行。然而，这些限制所带来的有限可用性直接导致开放式研究挑战，如半循环数据可用性和客户选择中可能存在的偏见，我们将在后面讨论。

### 1.2 联邦学习研究

本文的其余部分调查了许多由现实世界联邦学习算法的约束和挑战引起的开放问题，从医院系统的医疗数据训练模型到使用数亿移动设备进行训练。不用说，大多数致力于联邦学习问题的研究人员很可能不会部署生产的FL系统，也无法接触到数以百万计的实际设备。这就导致了激励工作的实际算法和模拟中进行的实验之间的关键区别，这些实验为激励问题的给定方法的适用性提供了证据。

这使得FL研究从实验的角度与其他ML领域有些不同，导致在进行FL研究时需要额外的考虑。特别是，当着重开放问题时，如果可能的话，我们也尝试指出可以在模拟中测量的相关性能指标，数据集的特征将使它们更能代表现实世界的性能，等等。模拟的需要也有分支的介绍FL研究。虽然我们无意成为权威或绝对的，但我们为介绍FL研究提出了以下适度的建议，以解决我们所描述的开放性问题：

* 如表1所示，FL算法可以包含广泛的问题。与算法和目标已经确定的领域相比，准确描述感兴趣的特定FL算法的细节是重要的，特别是当所提议的方法做出的假设可能不适用于所有算法时\(例如，有状态的客户参与所有回合\)。
* 当然，为了使研究可重复，任何模拟的细节都应该被展示出来。但是，为了有效地证明模拟问题的成功意味着对现实世界目标的有用进展，解释模拟是为了捕捉现实世界算法的哪些方面\(而不是哪些方面\)也是很重要的。我们希望本文中的指导将对此有所帮助。
* 在FL中，隐私和通信效率始终是首要问题，即使实验是在使用公共数据的单机上运行的模拟。与其他类型的ML相比，更重要的是，对于任何提出的方法来说，明确计算发生在哪里以及传递什么是很重要的。

联邦学习模拟软件库和标准数据集可以帮助缓解开展有效的FL研究的挑战；附录A总结了一些当前可用的选项。为不同的联邦学习算法\(跨设备和跨竖井\)开发标准评估指标和建立标准基准数据集仍然是当前工作的重要方向。

### 1.3 结构

第2节以表1的思想为基础，探讨了跨设备设置之外的其他FL设置和问题。第三部分将讨论关于如何提高联邦学习的效率和有效性的核心问题。第4节对威胁模型进行了仔细考虑，并考虑了实现严格隐私保护目标的一系列技术。与所有机器学习系统一样，在联邦学习应用程序中，可能存在操纵被训练模型的动机，各种类型的失败是不可避免的;这些挑战将在第5节中讨论。最后，我们在第6节中讨论了提供公平和无偏见模型的重要挑战。

## 2 提出核心FL假设：新兴算法和场景的应用

在本节中，我们将讨论与前一节中讨论的主题相关的研究领域。尽管这不是本文的重点，但这些领域的进展可以激励下一代生产系统的设计。

### 2.1 完全分散/点对点分布式学习

在联邦学习中，中央服务器协调训练过程，并接收所有客户端的贡献。因此，服务器是一个中心角色，它也可能代表一个单点故障。虽然大型公司或组织可以在某些应用程序场景中扮演这个角色，但在更具协作性的学习场景中，可靠且功能强大的中央服务器可能并不总是可用或可取的\[459\]。此外，当客户端数量非常大时，服务器甚至可能成为瓶颈，Lian等人\[305\]证明了这一点\(尽管这可以通过仔细的系统设计来减轻，例如\[81\]\)。

完全去中心化学习的关键思想是用个人客户端之间的对等通信来取代与服务器的通信。通信拓扑表示为一个连通图，其中节点为客户端，一条边表示两个客户端之间的通信通道。网络图通常选择最小最大度的稀疏网络图，使得每个节点只需要向少量节点发送或接收消息;这与服务器-客户机体系结构的星形图形成了对比。在完全去中心化的算法中，一轮对应于每个执行本地更新并与图2中的邻居交换信息的客户端。在机器学习的背景下，本地更新通常是一个本地\(随机\)梯度步骤，通信包括与邻居的本地模型参数的平均。请注意，不再像标准联邦学习中那样有模型的全局状态，但是可以将过程设计为所有本地模型收敛到所需的全局解决方案，也就是说，各个模型逐渐达成共识。虽然多智能体优化在控制领域有着悠久的历史，但最近人们在机器学习中考虑了SGD的完全分散变种和其他优化算法，以提高数据中心\[29\]的可伸缩性，以及用于分散的设备网络\[127,459,443,59,278,291,173\]。他们考虑了无向网络图，尽管在\[29,226\]中也研究过有向网络的情况\(编码可能出现在社会网络或数据市场等现实场景中的单向通道\)。

值得注意的是，即使在上面概述的分散算法中，一个中央权威机构仍然可能负责设置学习任务。例如，考虑以下问题：在分散的算法中，谁决定要训练什么模型？使用什么算法？超参数是什么？当某些东西不能按预期工作时，谁负责调试？要回答这些问题，仍然需要对中央权威机构中参与的客户有一定程度的信任。或者，决策可以由提出学习任务的客户做出，或者通过共识方案进行协作\(见第2.1.2节\)。

表3提供了联邦学习和对等学习之间的比较。虽然去中心化学习的架构假设与联邦学习不同，但它通常可以应用于类似的问题领域，出现了许多相同的挑战，并且在研究社区中存在显著的重叠。因此，我们在本文中也考虑了分散学习;在这部分挑战明确考虑了特定于分散方法的问题，但是在分散的情况下，其他部分中的许多开放问题也会出现。

![image-20210426145740565](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper4/table-3.png)

表3：联邦学习和完全分散学习之间的主要区别的比较。注意，与FL一样，分散学习可以进一步划分为不同的用例，其区别类似于表1中比较跨竖井和跨设备FL的区别。

#### 2.1.1 算法面临的挑战

在分散式机器学习方案的真实世界可用性这个话题上，仍有大量重要的算法问题有待解决。有些问题类似于使用中央服务器的联邦学习的特殊情况，而其他挑战则是完全去中心化或无信任的附加副作用。我们在下面概述了一些特定的领域。

**网络拓扑结构和异步对分布式SGD的影响** 完全分散的学习算法应该对有限的客户机可用性\(客户机在执行期间暂时不可用、退出或加入\)和有限的网络可靠性\(可能出现消息丢失\)具有鲁棒性。而对于特殊情况下的广义线性模型，使用对偶结构的方案可以实现这些期望的鲁棒性\[231\]，对于深度学习和SGD，这仍然是一个开放的问题。当网络图是完整的，但消息有固定的被丢弃概率时，Yu等人\[498\]表明，可以达到类似于可靠网络情况下的收敛速度。其他开放式研究问题涉及非iid数据分布、更新频率、有效通信模式和实际收敛时间\[443\]，我们将在下面更详细地概述。

连接良好或更密集的网络鼓励更快的共识，并给出更好的理论收敛速度，这取决于网络图的谱间隙。然而，当数据是IID时，稀疏拓扑在实践中并不一定会损害收敛：这在\[357\]中进行了理论分析。密集的网络通常会导致通信延迟，这种延迟随着节点度的增加而增加。大多数优化理论都没有明确考虑拓扑如何影响运行时，即完成每个SGD迭代所需的时钟时间。Wang等人\[469\]提出了一种基于匹配分解采样的分散SGD方法MATCHA，该方法在保持相同的误差收敛速度的同时，降低了任意给定节点拓扑的每次迭代通信时延。其关键思想是将图拓扑分解为可并行运行的不相交通信链路的匹配，并在每次迭代中仔细选择这些匹配的子集。这个子图序列导致在连接关键链路上有更多的频繁通信\(确保快速的错误收敛\)，在其他链路上有更少的频繁通信\(节省通信延迟\)。

去中心化SGD的算法自然也适合于异步算法，在这种算法中，每个客户端都在随机时间独立活动，从而消除了对全局同步的需求，并潜在地提高了可伸缩性\[127,459,59,29,306\]。

**本地更新分散SGD** 在通信轮前执行多个本地更新步骤的方案的理论分析比那些使用单个SGD步骤的方案\(如小批SGD\)更具挑战性。虽然这也将在后面的3.2节中讨论，但同样的情况也更普遍地适用于我们感兴趣的完全分散设置。依赖于单个本地更新步骤的方案通常被证明在非iid本地数据集的情况下是收敛的\[278,279\]。对于有几个本地更新步骤的情况，\[467,280\]最近提供了收敛性分析。此外，\[469\]为非iid数据案例提供了收敛分析，但针对上述基于匹配分解采样的具体方案。但是，一般来说，理解非iid数据分布下的收敛性以及如何设计一个模型平均策略来实现最快的收敛仍然是一个有待解决的问题。

**个性化和信任机制** 与跨设备FL算法类似，在对单个客户可用的非iid数据分发下的完全分散场景的一个重要任务是设计用于学习个性化模型集合的算法。\[459, 59\]的工作引入了完全分散的算法，通过平滑具有类似任务\(即类似数据分布\)的客户端的模型参数，协作学习每个客户端的个性化模型。Zantedeschi等\[504\]在个性化模型的基础上进一步学习了相似图。在去中心化设置中，一个关键的独特挑战仍然是此类方案对恶意参与者或不可靠数据或标签贡献的健壮性。将激励或机制设计与去中心化学习相结合是一个新兴的重要目标，如果没有可信的中央服务器，这可能更难实现。

**梯度压缩和量化方法** 在潜在的应用中，客户端通常在可用的通信带宽和允许的能源使用方面受到限制。在不影响收敛的情况下，将一些现有的压缩通信方案从集中式协调器方便设置\(见3.5节\)转换和归纳为完全分散算法是一个积极的研究方向\[278,391,444,279\]。一个补充的想法是设计分散的优化算法，自然会产生稀疏更新\[504\]。

**隐私** 在完全分散学习中，一个重要的挑战是防止任何客户机通过其共享更新重构另一个客户机的私有数据，同时为所学习的模型保持良好的实用水平。差异隐私\(见第4节\)是降低此类隐私风险的标准方法。在去中心化联邦学习中，这可以通过让每个客户端在本地添加噪声来实现，如\[239,59\]所做的那样。不幸的是，这种保护本地隐私的做法往往会在公用事业方面付出巨大代价。此外，为了提高标准FL算法见第4.4.3节\)中的隐私权衡而设计的基于安全聚合或安全洗排的分布式方法不容易与完全去中心的算法集成。在隐私和有效去中心化算法之间实现更好的权衡的可能方向是依靠去中心化本身来放大差异隐私保障，例如通过考虑适当放宽本地差异隐私\[146\]。

#### 2.1.2 实际挑战

对于完全分散学习来说，一个正交的问题是如何实际实现它。本节概述了基于分布式账本思想的一系列相关思想，但是还没有探索其他方法。

区块链是在不同用户之间共享的分布式账本，使数字交易\(包括加密货币交易\)成为可能，而没有一个中央权威机构。特别是，智能合约允许在区块链上执行任意代码，区块链本质上是一个大规模复制的最终一致的状态机。就联邦学习而言，使用该技术可以通过使用智能合约进行模型聚合来实现全球服务器的去中心化，其中执行智能合约的参与客户可以是不同的公司或云服务。

然而，在今天的区块链平台上，如以太坊\[478\]，区块链上的数据默认是公开可用的，这可能会阻碍用户参与去中心化联邦学习协议，因为数据保护通常是FL的主要激励因素。为了解决这些问题，修改现有的隐私保护技术以适应去中心化联邦学习的情况是可能的。首先，为了防止参与节点利用单独提交的模型更新，可以使用现有的安全聚合协议。Bonawitz等人提出了一种已经应用于跨设备FL的实用安全聚合协议\[80\]，以协议复杂性为代价有效地处理了退出参与者。另一个替代系统是让每个客户在区块链上存入一笔加密货币，如果他们在执行期间退出，就会受到惩罚。在不需要处理退出的情况下，可以显著简化安全聚合协议。实现安全聚合的另一种方法是使用机密智能合约，例如运行在安全飞地内的Oasis协议\[119\]所支持的。这样，每个客户机都可以简单地提交一个加密的本地模型更新，知道模型将通过远程认证在安全硬件中解密和聚合\(参见第4.1节中关于隐私的深入讨论\)。

为了防止任何客户端试图利用全局模型重构另一个客户端的私有数据，FL的客户级差异隐私\[338\]已经被提出。客户级差异隐私是通过在聚合全局模型上添加随机高斯噪声来实现的，该噪声足以隐藏任何单个客户端的更新。在区块链的背景下，每个客户端可以在经过本地梯度下降步骤后，本地添加一定量的高斯噪声，并将模型提交给区块链。应该计算本地噪声尺度，以便区块链上的聚合噪声能够实现与\[338\]中相同的客户端级差异隐私。最后，可以对区块链上的聚合全局模型进行加密，并且只有参与的客户端持有解密密钥，这将保护模型不被公开。

### 2.2 跨竖井联邦学习

与跨设备联邦学习\(见表1\)的特点相比，跨竖井联邦学习在总体设计的某些方面允许更多的灵活性，但同时也提出了实现其他属性可能比较困难的设置。本节将讨论其中的一些差异。

当许多公司或组织共享基于他们所有数据的模型训练动机，但不能直接共享他们的数据时，跨竖井设置可能是相关的。这可能是由于机密性的限制或法律限制，甚至是在单个公司内部，当它们不能在不同地理区域之间集中数据时。这些跨竖井的应用已经引起了大量的关注。

**数据分区** 在跨设备算法中，假设数据按示例进行分区。在跨竖井设置中，除了按示例进行分区外，按特性进行分区也具有实际意义。例如，当处于不同业务的两家公司拥有相同或重叠的客户集时，例如同一城市的一家本地银行和一家本地零售公司。Yang等人也将这种差异称为水平和垂直联合学习\[490\]。

基于特征划分数据的跨竖井FL，与基于实例划分数据的设置相比，采用了非常不同的训练架构。它可能会也可能不会涉及中央服务器作为中立方，客户端根据训练算法的具体情况，交换特定的中间结果，而不是模型参数，以协助其他方的梯度计算;参见例如\[490，第2.4.2节\]。在这种情况下，为了限制其他参与者通过观察训练过程可以推断出的信息量，已经提出了安全多方计算或同态加密等技术的应用。这种方法的缺点是，训练算法通常依赖于所追求的机器学习目标的类型。目前提出的算法包括树\[118\]、线性和逻辑回归\[490,224,316\]和神经网络\[317\]。与联邦平均相似的局部更新\(见第3.2节\)已被提出，以解决特征分区系统的通信挑战\[316\]，并\[238,318\]研究此类系统固有的安全和隐私相关挑战。

联邦迁移学习\[490\]是另一个概念，它考虑了具有挑战性的场景，其中数据各方只在用户空间或特征空间中共享部分重叠，并利用现有的迁移学习技术\[365\]协作构建模型。现有公式仅限于2个客户端的情况。

在跨竖井的FL中，当单个公司由于法律限制而不能集中数据时，或者当具有相似目标的组织希望协作改进模型时，按示例进行分区通常是相关的。例如，不同的银行可以协作训练用于欺诈检测的分类或异常检测模型\[476\]，医院可以构建更好的诊断模型\[139\]，等等。

支持上述应用程序的开源平台是联邦AI技术使能器\(F ATE\)\[33\]。与此同时，IEEE P3652.1联邦机器学习工作组正在致力于联邦人工智能技术框架的标准设置。其他平台包括关注一系列医疗应用的\[125\]和针对企业用例的\[321\]。详见附录A。

**激励机制** 诚信参与的激励机制设计除了发展新的算法技术外，也是一个重要的实践研究问题。这种需求可能出现在跨设备设置中\(例如\[261,260\]\)，但在跨竖井设置中尤其相关，其中的参与者可能同时也是业务竞争对手。奖励可以是货币奖励\[499\]或具有不同表现水平的最终模型\[324\]。在FL参与者之间存在竞争的合作学习情况下，交付与每个客户贡献相称的性能模型的选择尤其相关。客户可能会担心，将他们的数据贡献给培训联合学习模型将使他们的竞争对手受益，后者贡献没有那么多，但最终获得了相同的模型\(即搭便车问题\)。相关目标包括如何在贡献数据所有者之间分配联邦学习模型产生的收益，以维持长期参与，以及如何将激励与对抗敌对数据所有者的决策联系起来，以提高系统安全性，优化数据所有者的参与，提高系统效率。

**差异隐私** 第4.1节中对行动者和威胁模型的讨论在很大程度上也与跨竖井FL相关。然而，针对不同行动者的保护可能有不同的优先级。例如，在许多实际情况下，最终的培训模型将只发布给那些参加培训的人，这使得对“世界其他地方”的关注不那么重要。

另一方面，对于一个具有实际说服力的声明，我们通常需要一个本地差异隐私的概念，因为来自其他客户的潜在威胁可能更重要。在客户端不被认为是重大威胁的情况下，每个客户端可以控制来自多个各自用户的数据，在这样的用户级别上可能需要一个正式的隐私保证。根据应用情况，其他目标也值得追求。这一领域尚未进行系统的勘探。

**张量分解** 一些工作还研究了跨竖井联邦张量分解，其中多个站点\(每个站点都有一组具有相同特征的数据，即水平分区\)通过只与协调服务器共享中间因子，同时保持每个站点的数据私有，共同执行张量分解。在现有的工作中，\[272\]使用了基于交替方向乘子法\(ADMM\)的方法，\[325\]使用弹性平均SGD \(EASGD\)算法提高了效率，并进一步确保了中间因素的差异隐私。

### 2.3 分离学习

与以前侧重于数据分区和通信模式的设置相比，分离学习背后的关键思想\[215,460\]3是在客户机和服务器之间的每层基础上分割模型的执行。这既可以用于训练，也可以用于推理。

在分离学习的最简单配置中，每个客户端计算向前通过一个深度网络，直到一个称为切割层的特定层。切割层的输出，称为粉碎数据，被发送到另一个实体\(服务器或另一个客户端\)，由后者完成剩余的计算。这在不共享原始数据的情况下完成了一轮前向传播。然后，梯度可以以类似的方式从最后一层传播到切割层。切割层上的梯度——并且只有这些梯度——被发送回客户端，在那里完成其余的反向传播。这个过程一直持续到汇聚，而不需要客户端直接访问彼此的原始数据。图2\(a\)显示了这种设置，图2\(b\)显示了这种设置的变体，其中标签也没有与原始数据一起共享。根据特征划分数据的分离学习方法已经在\[101\]中进行了研究。

在一些情况下，\[421\]比较了分离学习和联邦学习的总体通信需求。分离学习在培训中引入了另一个并行性维度，即模型的各个部分之间的并行化，例如客户端和服务器。在\[245,240\]中，作者打破了部分网络之间的依赖关系，通过在不同部分并行化计算来减少总集中训练时间，这一思想在这里也可以适用。然而，如何在边缘设备上实现并行学习仍然是一个有待解决的问题。分离学习还支持将客户端模型组件与最佳的服务器端模型组件进行匹配，以实现模型的自动化选择，如ExpertMatcher\[413\]所示。

不过，通常情况下，传递的值可以揭示有关底层数据的信息。这在多大程度上以及是否可以接受，可能取决于应用程序和配置。NoPeek SplitNN\[462\]是一种分离学习的变体，它通过减少与原始数据的距离相关性\[461,442\]来减少潜在的泄漏，同时保持良好的模型性能通过分类交叉熵损失。其关键思想是最小化原始数据点与通信粉碎数据之间的距离相关性。如果不使用NoPeek SplitNN，被通信的对象可能包含与输入数据高度相关的信息，使用NoPeek SplitNN还允许根据它提供的去相关性相对较早地进行拆分。另一种工程驱动的方法是通过对客户端激活中出现的通道进行专门的修剪\[422\]来最小化分割学习中通信的信息量。总的来说，第4节中的很多讨论也与此相关，而且专门为分离学习提供正式的隐私保证的分析仍然是一个有待解决的问题。

### 2.4 执行概要

联邦学习的动机与许多相关领域的研究有关。

* 完全分散学习\(第2.1节\)无需中央服务器来协调整个计算。除了算法上的挑战，开放的问题是在这个想法的实际实现上，以及在理解建立任务需要什么样的可信任的中央权威上。
* 跨竖井联邦学习\(第2.2节\)承认不同类型的建模约束存在问题，如按示例和/或特征划分的数据，并在为客户制定正式的隐私保证或激励机制时面临不同的关注。
* 分离学习\(第2.3节\)是一种在客户端和服务器端之间分割模型执行的方法。它可以为整体的通信约束提供不同的选择，但是仍然缺少关于通信值何时显示敏感信息的详细分析。

