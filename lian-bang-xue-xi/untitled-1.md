# index

原文：[联邦学习的进展和有待解决的问题](https://export.arxiv.org/pdf/1912.04977)

## 摘要

联邦学习\(FL\)是一种机器学习方法，许多客户端\(例如移动设备或整个组织\)在中央服务器\(例如服务提供商\)的编排下协同训练一个模型，同时保持训练数据分散。FL体现了集中数据收集和最小化的原则，可以减轻许多由传统的、集中的机器学习和数据科学方法造成的系统性隐私风险和成本。由于FL研究的爆炸性增长，本文讨论了最近的进展，并提出了广泛的开放式问题和挑战。

## 1 介绍

联邦学习\(FL\)是一种机器学习方法，许多客户端\(例如移动设备或整个组织\)在中央服务器\(例如服务提供商\)的编排下协同训练一个模型，同时保持训练数据分散。它体现了集中收集和数据最小化的原则，可以减轻许多由传统的、集中的机器学习导致的系统性隐私风险和成本。从研究和应用的角度来看，这一领域最近受到了极大的关注。本文描述了联邦学习方法的定义特征和挑战，强调了重要的实践约束和注意事项，并列举了一系列有价值的研究方向。这项工作的目标是突出具有重大理论和实践兴趣的研究问题，并鼓励对可能有重大现实影响的问题的研究。

联邦学习这个术语是由McMahan等人在2016年引入的\[337\]:“我们将我们的方法称为联邦学习，因为学习任务是通过由中央服务器协调的参与设备\(我们称之为客户机\)的松散联邦来解决的。”跨大量通信带宽有限的不可靠设备的不平衡和非iid\(相同和独立分布\)数据分区被引入作为定义方面的挑战。

在联邦学习这个术语出现之前，就已经有了一些重要的相关工作。许多研究团体\(包括密码学、数据库和机器学习\)追求的一个长期目标是分析和学习分布在许多所有者之间的数据，而不暴露这些数据。在加密数据上计算的加密方法始于20世纪80年代早期\[396,492\]，Agrawal和Srikant\[11\]和Vaidya等人\[457\]是早期尝试使用集中式服务器从本地数据中学习并同时保护隐私的例子。相反，即使引入了联邦学习这个术语，我们也没有发现任何一项工作可以直接解决FL的所有挑战。因此，联邦学习这个术语为一组特征、约束和挑战提供了方便的简写，这些特征、约束和挑战经常同时出现在去中心化数据的应用ML问题中，而在去中心化数据中，隐私至关重要。

本文源自于谷歌西雅图办公室于2019年6月17 - 18日举办的联邦学习与分析研讨会。在这次为期两天的活动中，对联邦学习领域中许多开放式挑战进行广泛调查的必要性变得清晰起来。

讨论的许多问题的一个关键属性是，它们本质上是跨学科的——解决这些问题可能不仅需要机器学习，还需要来自分布式优化、密码学、安全、差异隐私、公平、压缩感知、系统、信息理论、统计学等方面的技术。许多最棘手的问题都处在这些领域的交叉点上，因此我们相信，协作将对持续的进展至关重要。这项工作的目标之一是强调这些领域的技术可以结合的方式，提出有趣的可能性和新的挑战。

自从术语联邦学习最初引入的重点是移动和边缘设备应用程序\(337、334\),对FL应用到其他应用程序的兴趣大大增加,其中一些可能只涉及少量的相对可靠的客户,例如多个组织合作训练模型。我们分别将这两个联邦学习方法称为“跨设备”和“跨竖井”。鉴于这些变化，我们提出了一个更广泛的联邦学习定义：

**联邦学习**是一种机器学习方法，在中央服务器或服务提供商的协调下，多个实体\(客户端\)协作解决机器学习问题。每个客户的原始数据存储在本地，不交换或转移;相反,有针对性的更新是狭义的更新，以包含手头特定学习任务所需的最低信息;在数据最小化服务中，尽可能早地执行聚合。我们注意到，这个定义将联邦学习与第2.1节中讨论的完全分散\(点对点\)学习技术区分开来。

虽然隐私保护数据分析的研究已经超过50年，但只有在过去的10年才有大规模的解决方案被广泛部署\(例如\[177,154\]\)。跨设备联邦学习和联邦数据分析正在应用于消费数字产品中。谷歌在Gboard移动键盘\[376,222,491,112,383\]以及Pixel手机\[14\]和Android Messages\[439\]中广泛使用了联邦学习。虽然谷歌是跨设备FL的先驱，但对这种方法的兴趣现在更广泛了，例如:苹果在iOS 13的\[25\]中使用跨设备FL，用于QuickType键盘和“Hey Siri”\[26\]的声音分类器;doc.ai 正在为医学研究开发跨设备的FL解决方案\[149\]，而Snips已经探索了用于热点词检测的跨设备FL\[298\]。

跨竖井应用也被提出或描述在无数领域，包括再保险的金融风险预测\[476\]、药品发现\[179\]、电子健康记录挖掘\[184\]、医疗数据分割\[15,139\]和智能制造\[354\]。

对联邦学习技术不断增长的需求导致了大量的工具和框架的出现。这些包括TensorFlow Federated \[38\]， Federated AI Technology Enabler \[33\]， PySyft \[399\]， Leaf \[35\]， PaddleFL\[36\]和Clara Training Framework \[125\];更多细节请参见附录a。商业数据平台联合联邦学习是由成熟的技术公司以及小型初创公司开发的。

表1对比了跨设备和跨竖井联邦学习与跨一系列轴的传统单数据中心分布式学习。这些特征建立了许多实际联邦学习系统通常必须满足的约束，因此既可以激励联邦学习，也可以告知联邦学习中的开放式挑战。它们将在接下来的章节中详细讨论。

![image-20210426105143687](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper4/table-1.png)

表1：联邦学习设置与数据中心中分布式学习的典型特征\(例如\[150\]\)。跨设备和跨竖井联邦学习是FL领域的两个例子，但并不打算详尽无遗。FL的主要定义特征以粗体突出，但其他特征在决定哪些技术适用时也是至关重要的。

这两种FL的变体被称为代表性和重要的例子，但不同的FL方法可能有这些特征的不同组合。在本文的其余部分，我们考虑跨设备的FL设置，除非另有说明，尽管许多问题也适用于其他FL设置。第2节专门讨论了许多其他变体和应用程序中的一些。

接下来，我们将更详细地考虑跨设备联邦学习，重点关注该技术典型大规模部署中常见的实际方面;Bonawitz等人\[81\]为特定的生产系统提供了更多的细节，包括对特定架构选择和考虑事项的讨论。

### 1.1 跨设备联邦学习设置

本节采用应用透视图，与前一节不同的是，不尝试定义透视图。相反，我们的目标是描述跨设备FL中的一些实际问题，以及它们如何适应更广泛的机器学习开发和部署生态系统。希望为接下来的开放问题提供有用的背景和动机，同时帮助研究人员估计在现实世界系统中部署一种特殊的新方法有多简单。在考虑FL训练过程之前，我们先画一个模型的生命周期草图。

#### 1.1.1 联邦学习模式的生命周期

FL过程通常是由为特定应用程序开发模型的模型工程师驱动的。例如，自然语言处理领域的专家可以开发一个用于虚拟键盘的下一个单词预测模型。图1显示了主要组件和参与者。在高层次上，典型的工作流是：

![image-20210426114546464](https://gitee.com/zlt_shadow/res/raw/master/images-bed/paper4/figure-1.png)

图1：经过fl训练的模型的生命周期和联邦学习系统中的各种参与者。第4节从威胁模型的角度重新讨论了该图。

1. **问题识别**：模型工程师识别一个需要用FL解决的问题。
2. **客户端检测**：如果需要，客户端\(例如手机上运行的应用程序\)被检测到本地存储必要的训练数据\(有时间和数量限制\)。在很多情况下，应用程序已经存储了这些数据\(例如，一个短信应用程序必须存储短信，一个照片管理应用程序已经存储照片\)。然而，在某些情况下，可能需要维护额外的数据或元数据，例如用户交互数据，为监督学习任务提供标签。
3. **仿真原型\(可选\)**：模型工程师可以使用代理数据集在FL模拟中对模型架构进行原型化并测试学习超参数。
4. **联邦模型训练**：启动多个联邦训练任务来训练模型的不同变体，或使用不同的优化超参数。
5. **\(联邦\)模型评估**：在任务得到充分训练之后\(通常是几天，如下\)，将对模型进行分析并选择好的候选者。分析可能包括在数据中心的标准数据集上计算的指标，或者联邦评估，其中将模型推到保留的客户端，对本地客户数据进行评估。
6. **部署**：最后，一旦一个好的模型被选中，它将经历一个标准的模型启动过程，包括手动质量保证，实时的A /B测试\(通常是在一些设备上使用新模型，在其他设备上使用上一代模型来比较它们的体内性能\)，以及分段推出\(以便在影响太多用户之前发现和回滚不良行为\)。模型的特定启动过程是由应用程序的所有者设置的，通常与模型如何训练无关。换句话说，这个步骤同样适用于经过联邦学习或传统数据中心方法训练的模型。

FL系统面临的主要实际挑战之一是使上述工作流程尽可能简单，理想地接近ML系统实现集中训练的易用性。虽然本文主要关注联邦训练，但还有许多其他组件，包括联邦分析任务，如模型评估和调试。改进这些是第3.4节的重点。现在，我们更详细地考虑单个FL模型的训练\(上面的第4步\)。

